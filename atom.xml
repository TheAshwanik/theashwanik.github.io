<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ashwani's Tech World - Giving back to community]]></title>
  <link href="http://blog.ashwani.co.in/atom.xml" rel="self"/>
  <link href="http://blog.ashwani.co.in/"/>
  <updated>2020-01-01T22:44:41+00:00</updated>
  <id>http://blog.ashwani.co.in/</id>
  <author>
    <name><![CDATA[Ashwani Kumar]]></name>
    <email><![CDATA[aryan.ashwani@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS Active Directory with OpenVPN]]></title>
    <link href="http://blog.ashwani.co.in/blog/2019-12-28/aws-active-directory-with-openvpn/"/>
    <updated>2019-12-28T00:00:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2019-12-28/aws-active-directory-with-openvpn</id>
    <content type="html"><![CDATA[<p>Many wonder what the benefits of Active Directory are in the modern era. We can leverage Active Directory to control access to resources. One absolutely great feature is Group Policy Objects (GPOs). GPOs enables seamless monitoring of Windows machines with Policies like OS updates, screen lock, and more.</p>




<p>Recently I did some probono work for one of the commpanies in UK and thought of documenting some setup required for <a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html">AWS MS Active Directory <!--more--> - Aka. Directory Services</a> and <a href="https://openvpn.net/vpn-server-resources/amazon-web-services-ec2-byol-appliance-quick-start-guide/">OpenVPN</a></p>




<h3>Prerequistites</h3>




<ol>
<li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_getting_started_create_directory.html">Launch Active Directory</a></li>
<li>Setup you own EC2 instance and install Open VPN, or <a href="https://aws.amazon.com/marketplace/pp/OpenVPN-Inc-OpenVPN-Access-Server/B00MI40CAE">Launch OpenVPN Access Server from AWS Market place</a></li>
<li>You will need an EC2 instance to manage the Active Directory objects, See further how to Install the Active Directory Administration Tools on Windows Server 2016</li>
</ol>




<h3>Target Architecture</h3>




<p><img src="http://blog.ashwani.co.in/assets/AWS-VPN-AD-Architeture.jpg" width="800" height="600" title="AWS-VPN-AD-Architeture" alt="AWS-VPN-AD-Architeture Image"></p>




<!-- <img style="-webkit-user-select: none;margin: auto;cursor: zoom-in;" src="https://lh3.googleusercontent.com/d/13tbYV0DdzptknM0VFIVWzDjrO3qxo76H?authuser=0"> -->




<h3>Active Directory Management</h3>




<p><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_manage_users_groups.html">Manage Users and Groups in AWS Managed Microsoft AD</a>  <br/>
<a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_manage_users_groups_create_user.html">Create User</a></p>




<h3>Manually Join EC2 Instance to the AD</h3>




<p>To <a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/join_windows_instance.html">manually join</a> an existing Amazon EC2 Windows instance to a Simple AD or AWS Directory Service for Microsoft Active Directory directory, the instance must be launched as specified in <a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/launching_instance.html">Seamlessly Join a Windows EC2 Instance</a></p>




<p>To join a Windows instance to a Simple AD or AWS Managed Microsoft AD directory <br/>
Connect to the instance using any Remote Desktop Protocol client. <br/>
Open the TCP/IPv4 properties dialog box on the instance. <br/>
Open Network Connections usisng command.    <br/>
<code>
%SystemRoot%\system32\control.exe ncpa.cpl
</code>  <br/>
Change the DNS server addresses, change the Preferred DNS server and Alternate DNS server addresses to the IP addresses of the AWS Directory Service-provided DNS servers.</p>




<p>Open the System Properties dialog box for the instance, select the Computer Name tab, and choose Change.  <br/>
<code>
Use command %SystemRoot%\system32\control.exe sysdm.cpl
</code></p>




<p>In the Member of field, select Domain, enter the fully-qualified name of your AWS Directory Service directory, and choose OK.  <br/>
When prompted for the name and password for the domain administrator, enter the username and password of an account that has domain join privileges.   <br/>
For more information about delegating these privileges, see Delegate Directory Join Privileges for AWS Managed Microsoft AD.</p>




<p>Note: <br/>
You can enter either the fully-qualified name of your domain or the NetBios name, followed by a backslash (), and then the user name, in this case, Admin. For example, corp.example.com\Admin or corp\Admin.</p>




<p>Restart the instance to have the changes take effect.</p>




<h3>To allow domain users RDP access to the domain joined Windows instances, follow these steps:</h3>




<p>You will get error "The connection was denied because the user account is not authorized for remote login."  <br/>
To solve it follow this:  <br/>
Connect to your Windows EC2 instance using RDP.   <br/>
Create a user. Repeat this step if you need more than one user.   <br/>
Create a security group.  <br/>
Add the new users to the new security group.  <br/>
Open Group Policy Management. Select your domain.s Forest, expand Domains, and then expand your domain name.  <br/>
Expand your delegated OU (NetBIOS name of the directory). Open the context (right-click) menu for Computers, and then choose Create a GPO in this domain, and Link it here.  <br/>
For Name, enter a name, and then choose Ok.   <br/>
In the navigation pane, expand Computers. Open the context (right-click) menu for the policy, and then choose Edit.   <br/>
In the Computer Configuration section of the navigation pane, expand Preferences, Control Panel Settings.  <br/>
Open the context (right-click) menu for Local Users and Groups, and then choose New, Local Group.   <br/>
For Group name, choose Remote Desktop Users (built-in), and then choose Add.    <br/>
For Name, enter the name of the security group that you created in step 3, and then choose Ok.  <br/>
This policy updates your environment at the next policy refresh interval. To force the policy to apply immediately, run the gpupdate /force command on the target server.</p>




<h3>Install the Active Directory Administration Tools on Windows Server 2016</h3>




<p>Open Server Manager from the Start screen by choosing Server Manager. <br/>
In the Server Manager Dashboard, choose Add roles and features, <br/>
In the Add Roles and Features Wizard choose Installation Type, select Role-based or feature-based installation, and choose Next.   <br/>
Under Server Selection, make sure the local server is selected, and choose Features in the left navigation pane.  <br/>
In the Features tree, open Remote Server Administration Tools, Role Administration Tools, select AD DS and AD LDS Tools, scroll down and select DNS Server Tools, and then choose Next.  <br/>
Review the information and choose Install. When the feature installation is finished, the Active Directory tools are available on the Start screen in the Administrative Tools folder.</p>




<h3>Manage GPO permissions</h3>




<p><a href="https://www.lepide.com/how-to/assign-permissions-to-files-folders-through-group-policy.html">..</a></p>




<h3>Open VPN</h3>




<p><a href="https://openvpn.net/vpn-server-resources/how-to-authenticate-users-with-active-directory/">Authenticate VPN using LDAP</a>   <br/>
<a href="https://openvpn.net/vpn-server-resources/openvpn-access-server-on-active-directory-via-ldap/">Authenticate VPN using LDAP - Another article</a></p>




<h4>Further Readings:</h4>




<p><a href="https://aws.amazon.com/blogs/security/how-to-set-up-dns-resolution-between-on-premises-networks-and-aws-using-aws-directory-service-and-microsoft-active-directory/">How to Set Up DNS Resolution Between On-Premises Networks and AWS Using AWS Directory Service and Microsoft Active Directory</a>    <br/>
<a href="https://aws.amazon.com/blogs/security/how-to-easily-log-on-to-aws-services-by-using-your-on-premises-active-directory/">How to Easily Log On to AWS Services by Using Your On-Premises Active Directory</a></p>




<p>Hope this will help someone.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Proxies Explained or Demystified]]></title>
    <link href="http://blog.ashwani.co.in/blog/2019-11-02/proxies-explained-or-demystified/"/>
    <updated>2019-11-02T00:00:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2019-11-02/proxies-explained-or-demystified</id>
    <content type="html"><![CDATA[<p>Proxy is Essentially, a middle man.
When dealing with computers the concept is largely the same. A web proxy is simply a bit of software that will relay a HTTP request for you.</p>




<p>This post is about - Proxies Made Easy or as my good friend at <a href="verygoodsecurity.com">very good security</a> say - "Proxies Demystified.."</p>




<h3>What is a Proxy</h3>




<p>HTTP Proxies are an essential component when using the internet day to day - load balancers, routers, content <!--more--> accelerators, content protection systems, these are all simple examples of web proxies and they all act as intermediaries to send your HTTP requests where they need to go, anonymize requests, handle routing of traffic, speed up the net, and many other uses.</p>




<p><a href="https://www.google.com/search?q=what+is+a+proxy">Google defines</a> a proxy as</p>




<pre><code>the authority to represent someone else
</code></pre>




<p>When it comes down to it, most web proxies fall into two camps:</p>




<ol>
<li><strong>Reverse Proxies</strong> - A reverse proxy is usually an internal-facing proxy used as a front-end to control and protect access to servers on a private network. A reverse proxy commonly also performs tasks such as load-balancing, authentication, decryption or caching.</li>
<li><strong>Forward Proxies</strong> - A forward proxy is an Internet-facing proxy used to retrieve from a wide range of sources.
Let.s look at these two types in more detail</li>
</ol>




<h3>What is a Reverse Proxy</h3>




<p>You.re probably using a reverse proxy in order to view this content. When you make a request to the server that serves this blog post it will pass through a load balancer. This load balancer is a type of reverse proxy. Reverse proxies will sit in front of one of more servers and distribute requests to these servers. Common examples of these would be Nginx.s proxy_pass module, HAProxy, Squid, and AWS. ELB.</p>




<p>Let.s look at an example of a reverse proxy:</p>




<p>Reverse Proxy
<a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg" alt="N|Solid" /></a></p>




<p>You can see in this graphic that the reverse proxy receives a request from a client on the internet and retrieves the requested resources from one of more servers that sit behind it. To the client there is no knowledge required of the servers (often called upstream servers) that serve the original content and they can be changed as required without any outside knowledge. The reverse proxy handles that information.</p>




<p>As part of this handling of the request the reverse proxy will often provide additional value such as terminating SSL, performing authentication and/or authorization, accelerating (caching or compressing) content or rewriting the request and/or response.</p>




<p>The word .reverse. in the name reverse proxy has no special meaning, it.s just used as the inverse of forward proxy which actually has a meaning as you.ll read shortly.</p>




<h3>What is a Forward Proxy</h3>




<p>Forward proxies are commonly used to control traffic leaving networks. When you send a request via the proxy it will .forward. your request on to the requested website, hence the name .Forward Proxy..</p>




<p>A common job of a forward proxy is to both control access to the internet by inspecting certain attributes as the request passes through it. If you.re on a corporate network and they prohibit you from going to a social network such as facebook.com, this will often be the job of a forward proxy. The forward proxy is able to inspect the host of the request and, since on a corporate network traffic is often mandated to flow through the proxy, it will deny any requests that use the prohibited host.</p>




<p>A similar implementation to the above will scan outbound content of the payload as it passes through the proxy. This can be used for a variety of data protection applications e.g., for data loss prevention; or scan content for malicious software.</p>




<p>Another common use-case for a forward proxy is to anonymize where the request originally came from.</p>




<p>Let.s look at an example of a forward proxy:</p>




<p>Forward Proxy
<a href="https://upload.wikimedia.org/wikipedia/commons/1/19/Forward_proxy_h2g2bob.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/1/19/Forward_proxy_h2g2bob.svg" alt="N|Solid" /></a></p>




<p>As you can see it sits in between requests from the user to the internet. As such, when the forward proxy sends a request to a host the host computer will see the IP address of the forward proxy, not of the user. This is commonly used to perform IP anonymization and is a major feature of VPNs.</p>




<h4>Layer 7 versus layer 3</h4>




<p>Most of the time .proxy. refers to a layer-7 application on the OSI reference model. However, another way of proxying is through layer-3 and is known as Network Address Translation (NAT). The difference between these two proxy technologies is the layer in which they operate, and the procedure to configuring the proxy clients and proxy servers.</p>




<p>Layer-7 proxies are more suitable if you.re inspecting the content of the payload to perform routing or otherwise manipulating the payload.</p>




<p>References  <br/>
   <a href="https://www.youtube.com/watch?v=s25cSWkGD38">Youtube link</a>  <br/>
   <a href="https://www.quora.com/Whats-the-difference-between-a-reverse-proxy-and-forward-proxy">Quora  - Whats-the-difference-between-a-reverse-proxy-and-forward-proxy</a>  <br/>
   <a href="http://www.jscape.com/blog/bid/87783/Forward-Proxy-vs-Reverse-Proxy">Jscape - Forward-Proxy-vs-Reverse-Proxy</a>   <br/>
   <a href="https://www.citrix.com/blogs/2010/10/04/reverse-vs-forward-proxy/">Citrix - reverse-vs-forward-proxy</a>  <br/>
   <a href="https://www.google.com/search?q=forward+versus+reverse+proxy">Google - forward+versus+reverse+proxy</a>  <br/>
   <a href="http://httpd.apache.org/docs/2.0/mod/mod_proxy.html#forwardreverse">Apache - mod_proxy.html#forwardreverse</a></p>




<p>Disclaimer:
**This is Collaboration post with verygoodsecurity.com and this post is directly published on collaboration request from Eugene - <a href="&#x6d;&#x61;&#x69;&#x6c;&#116;&#111;&#58;&#103;&#101;&#110;&#x65;&#x77;&#x61;&#108;&#x7a;&#x2e;&#120;&#120;&#x78;&#120;&#x40;&#103;&#x6d;&#97;&#x69;&#108;&#46;&#x63;&#111;&#x6d;">&#103;&#x65;&#110;&#x65;&#119;&#x61;&#x6c;&#122;&#x2e;&#x78;&#120;&#x78;&#x78;&#64;&#x67;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;</a>   <br/>
<a href="https://blog.verygoodsecurity.com/posts/proxies-demystified/">Original article</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HAProxy for load balancing]]></title>
    <link href="http://blog.ashwani.co.in/blog/2019-03-25/haproxy-for-load-balancing/"/>
    <updated>2019-03-25T00:00:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2019-03-25/haproxy-for-load-balancing</id>
    <content type="html"><![CDATA[<p>HAProxy, which stands for High Availability Proxy, is a popular open source software TCP/HTTP Load Balancer and proxying solution which can be run on Linux, Solaris.
Improves the performance and reliability of a server environment by distributing the traffic across servers (e.g. web, application, database).
It is used in many high-profile environments websites.</p>




<p>In this guide, I will provide a general overview of what HAProxy is, basic load-balancing terminology, and examples of how it might be <!--more--> used to improve the performance and reliability of your own server environment.</p>




<p>This post is about some setup required for <a href="http://cbonte.github.io/haproxy-dconv/1.9/intro.html">HAProxy</a></p>




<p>HAProxy can balance requests between any application that can handle HTTP or even TCP requests.</p>




<h3>Install HAProxy on Pi</h3>




<p>Credit goes to <a href="https://serversforhackers.com/c/load-balancing-with-haproxy">load-balancing-with-haproxy</a></p>




<pre><code>sudo apt-get update
sudo apt-get install -y haproxy
</code></pre>




<h3>HAProxy Configuration</h3>




<pre><code class="">
HAProxy configuration can be found at /etc/haproxy/haproxy.cfg. Here's what we'll likely see by default:

sudo vi /etc/haproxy/haproxy.cfg


global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin
        stats timeout 30s
        user haproxy
        group haproxy
        daemon

        # Default SSL material locations
        ca-base /etc/ssl/certs
        crt-base /etc/ssl/private

        # Default ciphers to use on SSL-enabled listening sockets.
        # For more information, see ciphers(1SSL). This list is from:
        #  https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
        # An alternative list with additional directives can be obtained from
        #  https://mozilla.github.io/server-side-tls/ssl-config-generator/?server=haproxy
        ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
        ssl-default-bind-options no-sslv3

defaults
        log     global
        mode    http
        option  httplog
        option  dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
        errorfile 400 /etc/haproxy/errors/400.http
        errorfile 403 /etc/haproxy/errors/403.http
        errorfile 408 /etc/haproxy/errors/408.http
        errorfile 500 /etc/haproxy/errors/500.http
        errorfile 502 /etc/haproxy/errors/502.http
        errorfile 503 /etc/haproxy/errors/503.http
        errorfile 504 /etc/haproxy/errors/504.http


frontend www-http
        bind *:80
        mode http
        default_backend http-nodes

frontend www-https
        bind *:443 ssl crt /etc/ssl/private/letsencrypt-ForHaproxy.pem
        reqadd X-Forwarded-Proto:\ https
        acl letsencrypt-acl path_beg /.well-known/acme-challenge/
        use_backend letsencrypt-backend if letsencrypt-acl
        default_backend http-nodes

backend letsencrypt-backend
        server letsencrypt 127.0.0.1:54321

backend http-nodes
        mode http
        balance roundrobin
        option forwardfor
        http-request set-header X-Forwarded-Port %[dst_port]
        http-request add-header X-Forwarded-Proto https if { ssl_fc }
        option httpchk HEAD / HTTP/1.1\r\nHost:localhost

        #redirect scheme https if !{ ssl_fc }
        server web01 127.0.0.1:9000 check
        server web02 127.0.0.1:9001 check


listen stats
        bind *:1936
        stats enable
        stats uri /
        stats hide-version
        stats auth username:password
</code></pre>




<h2></h2>




<h2>LetsEncrypt Certificate</h2>




<p>Use <a href="https://github.com/kshcherban/acme-nginx">acme-nginx</a> to generate letsencrypt site for your site.</p>




<pre><code>sudo cat /etc/ssl/private/letsencrypt-domain.key /etc/ssl/private/letsencrypt-domain.pem &gt; /etc/ssl/private/letsencrypt-ForHaproxy.pem
sudo mv letsencrypt-ForHaproxy.pem /etc/ssl/private/
sudo chown -R user:group /etc/ssl/private/letsencrypt-ForHaproxy.pem
</code></pre>




<h3>Resources</h3>




<p><a href="https://www.haproxy.org/they-use-it.html">Who is using HAProxy</a>  <br/>
<a href="http://cbonte.github.io/haproxy-dconv/1.9/intro.html">HAProxy Introduction</a> <br/>
<a href="https://serversforhackers.com/c/load-balancing-with-haproxy">https://serversforhackers.com/c/load-balancing-with-haproxy</a> <br/>
<a href="https://serversforhackers.com/c/using-ssl-certificates-with-haproxy">https://serversforhackers.com/c/using-ssl-certificates-with-haproxy</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PowerShell script to parse multiple Robocopy log files]]></title>
    <link href="http://blog.ashwani.co.in/blog/2019-01-12/powershell-script-to-parse-multiple-robocopy-log-files/"/>
    <updated>2019-01-12T10:56:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2019-01-12/powershell-script-to-parse-multiple-robocopy-log-files</id>
    <content type="html"><![CDATA[<p>Recently came across a problem of parsing a robocopy logs at work.
I found this helpful script, so reblogging for my future reference.</p>




<p> This is a PowerShell script that can be used to parse multiple Robocopy log files.</p>




<!--more-->




<p>Reference:<a href="http://www.chapmancentral.co.uk/cloudy/2013/02/23/parsing-robocopy-logs-in-powershell/">See more here</a></p>




<p>All credits to the respective authors. I am keeping this for future reference.
Hope this is fine.</p>




<h3>Robocopy Parser script</h3>




<pre><code>function Analyse-RC_Log {
    &lt;#
    .SYNOPSIS
        Robocopy log analyser
    .DESCRIPTION
        analysing the robocopy logs that are generated with the /LOG option.
        It has two modes, anaylsing the summary of log files and analyse the full log.
        The report is saved as a CSV file.
        Returns an custom object containing a RC summary like property, a CSV property.
        During script process the Culture of the script is changed to en-US for date and number interpretation / calculations

        Script is based on Robocopy log analyser from http://www.chapmancentral.co.uk/cloudy/2013/02/23/parsing-robocopy-logs-in-powershell/

    .EXAMPLE
        &gt;Analyse-RC_Log -SourcePath d:\RC_logdir -ExcelCSV -fp -unitsize GB
        Analyse log files in d:\RC_logdir, use a semicolon in the CSV file (conform MS Excel). Parse the complete log files and report al Bytes sizes as GB

    .EXAMPLE
        &gt;$Result=Analyse-RC_Log -SourcePath d:\RC_logdir -ExcelCSV -fp -unitsize GB
    &gt;&amp; $Result.ReportFileName
    &gt;$Result.Summary | out-gridview

    opens the CSV file and show the summary in a powershell gridview

    .PARAMETER fp
        File Parsing. Parse the complete file instead of the heather and footer

    .PARAMETER SourcePath
        Path where the Robocopy logs are saved.

    .PARAMETER ExcelCSV
        Use a semicolon as seperator

    .Parameter UnitSize
        Report al Byte sizes  in given unit size.

    .Link
        http://www.chapmancentral.co.uk/cloudy/2013/02/23/parsing-robocopy-logs-in-powershell/

    .NOTES
        File Name      : Analyse-RC_Log.ps1
        Author         : B. Lievers
        Prerequisite   : PowerShell V2 over Vista and upper.
        Copyright 2015 - Bart Lievers

    #&gt;

    [CmdletBinding()]

    param(
        [parameter(Position=0,Mandatory=$true,ValueFromPipeline=$false,HelpMessage='Source Path with no trailing slash')][string]$SourcePath,
        [switch]$fp,
        [Switch]$ExcelCSV,
        [Parameter(HelpMessage='Unit size, default is Bytes when parameter is not present')][ValidateSet("B","GB","KB","MB","TB")][string]$UnitSize
        )

    begin {
        [System.Globalization.CultureInfo]$culture=[System.Globalization.CultureInfo]("en-US")
        $OldCulture = [System.Threading.Thread]::CurrentThread.CurrentCulture
        trap 
        {
            [System.Threading.Thread]::CurrentThread.CurrentCulture = $OldCulture
        }
        [System.Threading.Thread]::CurrentThread.CurrentCulture = $culture
        Write-Verbose ("Changing Locale from "+$oldCulture.Name+" to "+$culture.Name)

        write-host "Robocopy log parser. $(if($fp){"Parsing file entries"} else {"Parsing summaries only, use -fp to parse file entries"})"

        $ElapsedTime = [System.Diagnostics.Stopwatch]::StartNew()
        $refreshrate=1 # progress counter refreshes this often when parsing files (in seconds)

        #region initialize header fields
        # These summary fields always appear in this order in a robocopy log
        $HeaderParams = @{
            "04|Started" = "date";  
            "01|Source" = "string";
            "02|Dest" = "string";
            "03|Options" = "string";
            "07|Dirs" = "counts";
            "08|Files" = "counts";
            "09|Bytes" = "counts";
            "10|Times" = "counts";
            "05|Ended" = "date"
            #"06|Duration" = "string"
        }
        #-- summary fields for file tag statistics during file parsing, swich -fp
        $fileTags=@{ 
            "01|MISMATCH" = ""
            "02|EXTRA file" = ""
            "03|New File" = ""
            "04|lonely" = ""
            "05|Newer" = ""
            "06|Newer XN" = ""
            "07|Older" = ""
            "08|Older XO" = ""
            "09|Changed" = ""
            "10|Changed XC" = ""
            "11|Tweaked" = ""
            "12|Same IS" = ""
            "13|Same" = ""
            "14|attrib" = ""
            "15|named" = ""
            "16|large" = ""
            "17|small" = ""
            "18|too old" = ""
            "19|too new" = ""
            "20|New Dir"= ""
        }
        #-- summary fields for directory tag statistics during file parsing, swich -fp
        $DirTags=@{ 
            "01|MISMATCH" = ""
            "02|Extra Dir" = ""
            "03|New Dir" = ""
            "04|lonely" = ""
            "05|named" = ""
            "06|junction" = ""
            "07|exist" = ""
        } 

        $ProcessCounts = @{
            "Processed" = 0;
            "Error" = 0;
            "Incomplete" = 0
        }
        #endregion

        #-- Default the CSV delim is a comma, when using CSV for Excel a semicolon is needed as delimmiter
        if ($ExcelCSV) { $Delim=";"} else {$Delim=","}
         #-- ASCII tab character
        $tab=[char]9

         #-- Get list of files to analyse
        $files=get-childitem $SourcePath
        #-- let's start writing, shall we ? 
        $writer=new-object System.IO.StreamWriter("$(get-location)\robocopy-$(get-date -format "dd-MM-yyyy_HH-mm-ss").csv")


        #region private functions

        function Get-Tail{
            &lt;#
            .SYNOPSIS
                Get tail of file
            .EXAMPLE
                &gt;Get-Tail $reader 20
            .PARAMETER reader
                an IO stream file object
            .PARAMETER count
                Number of rows to collect
            #&gt;
            Param (
                [object]$reader, 
                [int]$count = 10
                )

            $lineCount = 0
            [long]$pos = $reader.BaseStream.Length - 1

            while($pos -gt 0) {
                $reader.BaseStream.position=$pos

                # 0x0D (#13) = CR
                # 0x0A (#10) = LF
                if ($reader.BaseStream.ReadByte() -eq 10) {
                    $lineCount++
                    if ($lineCount -ge $count) { break }
                    }
                $pos--
                } 

            # tests for file shorter than requested tail
            if ($lineCount -lt $count -or $pos -ge $reader.BaseStream.Length - 1) {
                $reader.BaseStream.Position=0
            } else {
                # $reader.BaseStream.Position = $pos+1
            }

            $lines=@()
            while(!$reader.EndOfStream) {
                $lines += $reader.ReadLine()
            }
            return $lines
        }

        function Get-Top {
            &lt;#
            .SYNOPSIS
                Get top of file
            .EXAMPLE
                &gt;Get-Top $reader 20
            .PARAMETER reader
                an IO stream file object
            .PARAMETER count
                Number of rows to collect
            #&gt;
            Param(
                [object]$reader,
                [int]$count = 10
            )

            $lines=@()
            $lineCount = 0
            $reader.BaseStream.Position=0
            while(($linecount -lt $count) -and !$reader.EndOfStream) {
                $lineCount++
                $lines += $reader.ReadLine()        
            }
            return $lines
        }

        function Remove-Key{
            &lt;#
            .SYNOPSIS
                Return the name without the ID
            .EXAMPLE
                &gt;Remove-Key -name "01|example"
            .PARAMETER name
                a string where the ID needs to be stripped
            #&gt;
            Param ( $name 
            )
            if ( $name -match "|") {
                return $name.split("|")[1]
            } else {
                return ( $name )
            }
        }

        function Get-Value{
            &lt;#
            .SYNOPSIS
                Get the value of a RC line
            .EXAMPLE
                &gt;Get-Value -line " filecount : 35555" -variable "Filecount"
                Returns 35555
            .PARAMETER line
                A RC log string
            .PARAMETER variable
                The variable that needs to be extracted
            #&gt;
            Param(
                $line,
                $variable
            )
            if ($line -like "*$variable*" -and $line -like "* : *" ) {
                $result = $line.substring( $line.IndexOf(":")+1 )
                return $result 
            } else {
                return $null
            }
        }

        function UnBodge-Date{
            &lt;#
            .SYNOPSIS
                Convert Robocopy date to a usable format
            .EXAMPLE
                &gt;UnBodge-Date -dt "Sat Feb 16 00:16:49 2013"
                Returns 16-02-2013 00:16:49 in Locale format
            .PARAMETER dt
            #&gt;
            Param(
                $dt
            )
            # Fixes RoboCopy botched date-times in format Sat Feb 16 00:16:49 2013
            if ( $dt -match ".{3} .{3} \d{2} \d{2}:\d{2}:\d{2} \d{4}" ) {
                $dt=$dt.split(" ")
                $dt=$dt[2]+"/"+$dt[1]+"/"+$dt[4],$dt[3]
                $dt -join " " | Out-Null
            }
            if ( $dt -as [DateTime] ) {
                return(get-date $dt -format "dd/MM/yyy HH:mm:ss")
            } else {
                return $null
            }
        }

        function Unpack-Params{
            &lt;#
            .SYNOPSIS
                Unpacks file count bloc in the format
                 Dirs :      1827         0      1827         0         0         0
                Files :      9791         0      9791         0         0         0
                Bytes :  165.24 m         0  165.24 m         0         0         0
                Times :   1:11:23   0:00:00                       0:00:00   1:11:23
                Parameter name already removed
            .EXAMPLE
                &gt;UnBodge-Date -dt "Sat Feb 16 00:16:49 2013"
                Returns 16-02-2013 00:16:49 in Locale format
            .PARAMETER params

            #&gt;
            Param(
                $params
            )

            if ( $params.length -ge 58 ) {
                $params = $params.ToCharArray()
                $result=(0..5)
                for ( $i = 0; $i -le 5; $i++ ) {
                    $result[$i]=$($params[$($i*10 + 1) .. $($i*10 + 9)] -join "").trim()
                }
                #$result=$result -join ","
                $result=$result -join $Delim
            } else {
                #$result = ",,,,,"
                $result=$Delim+$Delim+$Delim+$Delim+$Delim
            }
            return $result
        }
    #endregion        
    } #-- end of Begin

    Process{
    $sourcecount = 0
        $targetcount = 1

        #region construct the header line of the CSV
    $writer.Write("File")
    $fields="File"
    foreach ( $HeaderParam in $HeaderParams.GetEnumerator() | Sort-Object Name ) {
        if ( $HeaderParam.value -eq "counts" ) {
            $tmp="~ Total"+$Delim+"~ Copied"+$Delim+"~ Skipped"+$Delim+"~ Mismatch"+$Delim+"~ Failed"+$Delim+"~ Extras"
            if ((Remove-Key $headerparam.name) -match "Bytes") {
                #-- if column header is a Bytes Column then match it to the unitsize
                if ($UnitSize -and $UnitSize -ne "B") {
                    #-- change the Bytes header according to the unitsize, Unitsize is GB ==&gt; header is GBytes
                    $tmp=$tmp.replace("~",$UnitSize.Substring(0,1)+ "$(Remove-Key $headerparam.name)")
                } else {
                    $tmp=$tmp.replace("~","$(Remove-Key $headerparam.name)")
                }
            } else {
                $tmp=$tmp.replace("~","$(Remove-Key $headerparam.name)")
            }
            $fields=$fields+$Delim+"$($tmp)"
            $writer.write($Delim+"$($tmp)")
        } else {
            $writer.write($Delim+"$(Remove-Key $HeaderParam.name)")
            $fields=$fields+$Delim+"$(Remove-Key $HeaderParam.name)"
        }
    }

    if($fp){
        $writer.write($Delim+"Scanned"+$Delim+"Newest"+$Delim+"Oldest")
        $fields=$fields+$Delim+"Scanned"+$Delim+"Newest"+$Delim+"Oldest"
        foreach ($fileTag in $filetags.GetEnumerator() | Sort-Object Name ) {
            $writer.write($Delim+$filetag.name.split("|")[1])
             $fields=$fields+$delim+$filetag.name.split("|")[1]
                }
        foreach ($DirTag in $Dirtags.GetEnumerator() | Sort-Object Name ) {
            $writer.write($Delim+"DIR "+$DirTag.name.split("|")[1])
             $fields=$fields+$delim+"DIR "+$DirTag.name.split("|")[1]
        }
    }
     # EOL
    $writer.WriteLine()
    #endregion

        $table=$fields
        $filecount=0

        # Enumerate the files
        foreach ($file in $files) {  
            $filecount++
            write-host "$filecount/$($files.count) $($file.name) ($($file.length) bytes)"
            $results=@{}
            #-- open the file
            $Stream = $file.Open([System.IO.FileMode]::Open, 
                           [System.IO.FileAccess]::Read, 
                            [System.IO.FileShare]::ReadWrite) 
            $reader = New-Object System.IO.StreamReader($Stream) 

            $HeaderFooter = Get-Top $reader 16

            if ( $HeaderFooter -match "ROBOCOPY     ::     Robust File Copy for Windows" ) {
                #-- file has valid header
                if ( $HeaderFooter -match "Files : " ) {
                    $HeaderFooter = $HeaderFooter -notmatch "Files : "
                }

                [long]$ReaderEndHeader=$reader.BaseStream.position

                $Footer = Get-Tail $reader 16
                #check footer of file
                $ErrorFooter = $Footer -match "ERROR \d \(0x000000\d\d\) Accessing Source Directory"
                if ($ErrorFooter) {
                    $ProcessCounts["Error"]++
                    write-host -foregroundcolor red "`t $ErrorFooter"
                } elseif ( $footer -match "---------------" ) {
                    $ProcessCounts["Processed"]++
                    $i=$Footer.count
                    while ( !($Footer[$i] -like "*----------------------*") -or $i -lt 1 ) { $i-- }
                    $Footer=$Footer[$i..$Footer.Count]
                    $HeaderFooter+=$Footer
                } else {
                    $ProcessCounts["Incomplete"]++
                    #write-host -foregroundcolor yellow "`t Log file $file is missing the footer and may be incomplete"
                    write-warning "`t Log file $file is missing the footer and may be incomplete"
                }

                foreach ( $HeaderParam in $headerparams.GetEnumerator() | Sort-Object Name ) {
                    $name = "$(Remove-Key $HeaderParam.Name)"
                    $tmp = Get-Value $($HeaderFooter -match "$name : ") $name
                    if ( $tmp -ne "" -and $tmp -ne $null ) {
                        switch ( $HeaderParam.value ) {
                            "date" { $results[$name]=UnBodge-Date $tmp.trim() }
                            "counts" { $results[$name]=Unpack-Params $tmp }
                            "string" { $results[$name] = """$($tmp.trim())""" }     
                            default { $results[$name] = $tmp.trim() }       
                        }
                    }
                    #-- convert bytes statistics to numbers
                    if ($name -eq "Bytes" -and ($results[$name] -ne $null)) {
                        $tmp=@()     
                        $results[$name].split($Delim) | % {
                            #-- convert value to MBytes 
                            $Bytes=$_
                            if ($Bytes -match "m|g|t|k") {
                                switch ($Bytes.split(" ")[1]) {                
                                    "m" {$conv=1MB*$Bytes.replace(" m","MB")/1MB}
                                    "k" {$conv=1KB*$Bytes.replace(" k","KB")/1KB}
                                    "g" {$conv=1GB*$Bytes.replace(" g","GB")/1GB}
                                    "t" {$conv=1TB*$Bytes.replace(" t","TB")/1TB}
                                }
                            } else { 
                                #-- copy original value, no unit sign detected
                                $conv = $Bytes
                            }
                            #-- convert size 
                            switch ($UnitSize) {
                                "MB" {$tmp+=($conv/1MB)}
                                "KB" {$tmp+=($conv/1KB)}
                                "GB" {$tmp+=($conv/1GB)}
                                "TB" {$tmp+=($conv/1TB)}
                                default {$tmp+=($conv)} #-- no conversion needed. Size is in Bytes
                            }              
                        }
                        #-- rebuild string
                        $results[$name]=$tmp -join $delim                    
                    } #-- end of converting bytes statistics          
                } #-- end of parsing headerparam fields


                if ( $fp ) {
                    #-- parse the complete file
                    write-host "Parsing $($reader.BaseStream.Length) bytes" -NoNewLine

                    # Now go through the file line by line
                    $FT_counters=@{}
                    $DT_counters=@{}
                    $FileTags.GetEnumerator() | select name | %{ $FT_counters.add($_.name.split("|")[1],0)}
                    $DirTags.GetEnumerator() | select name | %{ $DT_counters.add($_.name.split("|")[1],0)}
                    $reader.BaseStream.Position=0
                    $filesdone = $false
                    $linenumber=0
                    $FileResults=@{}
                    $newest=[datetime]"1/1/1900"
                    $oldest=Get-Date
                    $linecount++
                    $firsttick=$elapsedtime.elapsed.TotalSeconds
                    $tick=$firsttick+$refreshrate
                    $LastLineLength=1

                    try {
                        do {
                            $line = $reader.ReadLine()
                            $linenumber++
                            if (($line -eq "-------------------------------------------------------------------------------" -and $linenumber -gt 16)  ) { 
                                # line is end of job
                                $filesdone=$true
                            } elseif ($linenumber -gt 16 -and $line -gt "" ) {
                                #-- split line according to TAB
                                $buckets=$line.split($tab)

                                if ( $buckets.count -gt 3 ) {
                                    #-- line contains file information
                                    $status=$buckets[1].trim()
                                    $FileResults["$status"]++
                                    #-- File tag counters
                                    if ($status -ceq "Newer") { $FT_counters["$status" +" XN"]++ }
                                    elseif ($status -ceq "Older") {  $FT_counters["$status" +" XO"]++ } 
                                    elseif ($status -ceq "Changed") {  $FT_counters["$status" +" XC"]++ }
                                    elseif ($status -ceq "same") {  $FT_counters["$status" +" IS"]++ }
                                    else {$FT_counters["$status"]++}

                                    #-- Get Timestamp from file
                                    $SizeDateTime=$buckets[3].trim()
                                    if ($sizedatetime.length -gt 19 ) {
                                        $DateTime = $sizedatetime.substring($sizedatetime.length -19)
                                        if ( $DateTime -as [DateTime] ){
                                            $DateTimeValue=[datetime]$DateTime
                                            if ( $DateTimeValue -gt $newest ) { $newest = $DateTimeValue }
                                            if ( $DateTimeValue -lt $oldest ) { $oldest = $DateTimeValue }
                                        }
                                    }
                                } elseif ($buckets.count -eq 3) {
                                    #-- line contains directory information
                                    #-- Directory tag counters
                                    $status=$buckets[1].Substring(0,10).trim()
                                    if ($status.length -gt 0){
                                        $DT_counters["$status"]++
                                    } else {
                                        $DT_counters["Exist"]++
                                    }
                                }
                            }

                            #-- progress indicator 
                            if ( $elapsedtime.elapsed.TotalSeconds -gt $tick ) {
                                $line=$line.Trim()
                                if ( $line.Length -gt 48 ) {
                                    $line="[...]"+$line.substring($line.Length-48)
                                }
                                $line="$([char]13)Parsing &gt; $($linenumber) ($(($reader.BaseStream.Position/$reader.BaseStream.length).tostring("P1"))) - $line"
                                write-host $line.PadRight($LastLineLength) -NoNewLine
                                $LastLineLength = $line.length
                                $tick=$tick+$refreshrate                        
                            }

                        } until ($filesdone -or $reader.endofstream)
                    }
                    finally {
                        $reader.Close()
                    }

                    $line=$($([string][char]13)).padright($lastlinelength)+$([char]13)
                    write-host $line -NoNewLine
                }

                #-- write results
                $writer.Write("`"$file`"")
                $line="`"$file`""
                #-- write values
                foreach ( $HeaderParam in $HeaderParams.GetEnumerator() | Sort-Object Name ) {
                    $name = "$(Remove-Key $HeaderParam.Name)"
                    if ( $results[$name] ) {
                        $writer.Write("$Delim$($results[$name])")
                        $line=$line+"$Delim$($results[$name])"
                    } else {
                        if ( $ErrorFooter ) {
                            #-- placeholder
                        } elseif ( $HeaderParam.Value -eq "counts" ) {
                            #-- write summary counters
                            $writer.Write($Delim+$Delim+$Delim+$Delim+$Delim+$Delim)
                            $line=$line+"$Delim$($results[$name])"
                        } else {
                            $writer.Write($Delim) 
                            $line=$line+"$Delim$($results[$name])"
                        }
                    }
                }

                if ( $ErrorFooter ) {
                    $tmp = $($ErrorFooter -join "").substring(20)
                    $tmp=$tmp.substring(0,$tmp.indexof(")")+1)+$Delim+$tmp
                    $writer.write($delim+$delim+"$tmp")
                    $line=$line+"$Delim$($results[$name])"
                } elseif ( $fp ) {
                    #-- write values from file parsing      
                    $writer.write($delim+"$LineCount"+$delim+"$($newest.ToString('dd/MM/yyyy hh:mm:ss'))"+$delim+"$($oldest.ToString('dd/MM/yyyy hh:mm:ss'))")      
                    $line=$line+"$Delim$($results[$name])"
                    #-- write File tag counters 
                    foreach ($fileTag in $filetags.GetEnumerator() | Sort-Object Name ) {
                    $writer.write($delim+"$($FT_counters[$Filetag.name.split("|")[1]])")
                    $line=$line+$delim+$($FT_counters[$Filetag.name.split("|")[1]])
                    }
                    #-- write directory tag counters
                    foreach ($DirTag in $DirTags.GetEnumerator() | Sort-Object Name ) {
                    $writer.write($delim+"$($DT_counters[$dirtag.name.split("|")[1]])")
                    $line=$line+$delim+$($dT_counters[$DirTag.name.split("|")[1]])
                    }
                }
                #-- EOL
                $writer.WriteLine()
                $table=$table+"`n"+$line
            } else {
                #-- file is not a RoboCopy log file
                #write-host -foregroundcolor darkgray "$($file.name) is not recognised as a RoboCopy log file"
                write-warning "$($file.name) is not recognised as a RoboCopy log file"
            }
        }
    } #- -end of Process

    End{
        #-- write and output results
        write-host "$filecount files scanned in $($elapsedtime.elapsed.tostring()), $($ProcessCounts["Processed"]) complete, $($ProcessCounts["Error"]) have errors, $($ProcessCounts["Incomplete"]) incomplete"
        write-host  "Results written to $($writer.basestream.name)"
        $CSVFile=$writer.basestream.name
        $writer.close() #-- yes, we are done writing
        #-- create output object, containing name of CSV file and Report object
        $Output=New-Object -TypeName psobject -Property @{ReportFileName=$CSVFile
                                                          Report=ConvertFrom-Csv -Delimiter $Delim -InputObject $table
                                                          Summary=@()}

        #-- summize, build a Robocopy like Summary
        $Types=@("Dirs","Files",("Bytes".replace("B",$SizeUnit)),"Times","Speed")
        $types | % {
            $row= "" | select  Type,Total,Copied,Skipped,Mismatch,FAILED,Extras
            $row.type=$_
            if ($row.type -ilike "Times") { 
                #-- calculate times
                $Output.Report | %{
                    if ($_.ended.length -gt 0){
                        #-- only use data from complete RC logs
                        $row.total=$row.total+[timespan]$_."Times Total"
                        $row.Failed=$row.Failed+[timespan]$_."Times Failed"
                        $row.Copied=$row.Copied+[timespan]$_."Times Copied"
                        $row.Extras=$row.Extras+[timespan]$_."Times Extras"   
                    } else {
                        Write-Verbose ("RC log "+$_.file+" skipped for summary calculation. Log file is not complete.")
                    }     
                }
            } elseif ($row.type -ilike "Speed") {
                #-- Calculate speed
                $Duration=0
                $output.Report | %{
                        if ($_.ended.length -gt 0){
                            #-- only use data from complete RC logs
                            $Duration=$Duration+[timespan]$_."Times Copied"
                        }
                    }
                $row.Copied="{0:N1}" -F ((($output.report | Measure-Object -Property (("Bytes".replace("B",$SizeUnit))+" Copied") -Sum).sum) / $Duration.seconds)
            } else {
                #-calculate counters

                Write-Verbose ("%%%%%%%%%%%%%%%%%%%%"+$row.type)

                $row.Total="{0:N1}" -f ($output.report | Measure-Object -Property ($row.type+" Total") -Sum).sum
                $row.Copied="{0:N1}" -f($output.report | Measure-Object -Property ($row.type+" Copied") -Sum).sum
                $row.Skipped="{0:N1}" -f($output.report | Measure-Object -Property ($row.type+" Skipped") -Sum).sum
                $row.Mismatch="{0:N1}" -f($output.report | Measure-Object -Property ($row.type+" Mismatch") -Sum).sum
                $row.Failed="{0:N1}" -f($output.report | Measure-Object -Property ($row.type+" Failed") -Sum).sum
                $row.Extras="{0:N1}" -f($output.report | Measure-Object -Property ($row.type+" Extras") -Sum).sum
            }
            $Output.Summary+=$row
        }
        [System.Threading.Thread]::CurrentThread.CurrentCulture = $OldCulture
        Write-Verbose ("Changed Locale back to "+$oldCulture.Name)
        return($output) #-- done, fini, finaly....
    } #-- end of End
}

Analyse-RC_Log -SourcePath C:\Desktop\ServerLog.txt -ExcelCSV -fp -unitsize
</code></pre>




<p>== <Robocopy Log file format></p>




<pre><code>-------------------------------------------------------------------------------
   ROBOCOPY     ::     Robust File Copy for Windows                              
-------------------------------------------------------------------------------

  Started : Wed Nov 15 21:05:18 2015

   Source : E:\DATA\SomeStagingDir\
     Dest : \\DestinationServer\\SomeStagingDir\SomeDir\

    Files : *.zip

  Options : /FFT /V /S /E /COPY:DAT /Z /MAXAGE:5 /IPG:100 /R:0 /W:1 

------------------------------------------------------------------------------

                       0    E:\DATA\SomeStagingDir\
    *EXTRA Dir        -1    \\DestinationServer\\SomeStagingDir\SomeDir\Lxx\
    *EXTRA Dir        -1    \\DestinationServer\\SomeStagingDir\SomeDir\New folder\
    *EXTRA Dir        -1    \\DestinationServer\\SomeStagingDir\SomeDir\nxx1\
                       1    E:\DATA\SomeStagingDir\Server_1\
        New File           1.8 m    Server_1.log.zip
2015/11/15 21:05:18 ERROR 112 (0x00000070) Copying File E:\DATA\SomeStagingDir\Server_1\Server_1.log.zip
There is not enough space on the disk.



------------------------------------------------------------------------------

               Total    Copied   Skipped  Mismatch    FAILED    Extras
    Dirs :         2         0         2         0         0         3
   Files :         1         0         0         0         1         0
   Bytes :    1.82 m         0         0         0    1.82 m         0
   Times :   0:00:00   0:00:00                       0:00:00   0:00:00

   Ended : Wed Nov 25 20:05:18 2015
</code></pre>




<p>Thank You..</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Search string faster with Ruby]]></title>
    <link href="http://blog.ashwani.co.in/blog/2018-07-20/search-string-faster-with-ruby/"/>
    <updated>2018-07-20T15:59:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2018-07-20/search-string-faster-with-ruby</id>
    <content type="html"><![CDATA[<p>Is grep Slow?   Sure it is. Read on..
Just a few days back there was an electrical outage and lot of applications were dead. <br/>
In one case, lot of customer orders could   <!--more--> not be processed.
Hence, there rose a need of manual intervention and extraction of orders (XML) from a logfile and re-feeding them to another system.
The task was simple, I had order numbers in orders.txt  and I had to write a shell script to grep for a particular
xml containing each of these orders, extract XML and create a file for each order.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Shell script to loop and find an order in another file</span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat extract.sh
</span><span class='line'>--------------
</span><span class='line'>i=0
</span><span class='line'>echo "Extraction Script Started at:" `date`
</span><span class='line'>while read order_id; do
</span><span class='line'>  filename=$order_id"_tmp.xml"
</span><span class='line'>  finalfilename=$order_id".xml"
</span><span class='line'>  grep ".*$order_id." *.log > $filename && echo "written xml for $order_id in $filename" || echo $order_id >> Orders_not_found.txt
</span><span class='line'>  cat $filename | sed -e 's|text-to-remove|new-text|g' | sed -e 's|\*\*\*||g' > $finalfilename
</span><span class='line'>  rm $filename
</span><span class='line'>  ((i++))
</span><span class='line'>done &lt; orders.txt
</span><span class='line'>echo "Extraction Script Ended at:" `date`</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>But the problem was that the log file in which I was searching was too huge. It was 5GBs in total.
Hence the grep was taking minimum 4-5 Minutes to search one order and create an xml file for that.
Clearly this was not a solution, as I had to find thousand orders in those log files and it was very critical for end customer.</p>




<p>If my calulation was right, I had to spend:  <br/>
4 Mins = 1 Xml  <br/>
60 Mins = 1 Hr = 15 Xml  <br/>
at this rate I would have spent atleast 3-4 days CPU time , to get all those 1000 XMLs.
(Not to mention the pain of getting screwed and frustration). Meaning which, we all would have been screwed
over and over again for 3-4 days by the customer.</p>




<p><b>Enter Ruby:</b>
One liner saved us.  <br/>
I used this ruby command, to first find the relevant generic string then create order xml files using a normal shell
script as above. I thought I would keep this fir future reference.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ruby -pe 'next unless $_ =~ /&lt;RegExp for stringtomatch>.*Number.*/' &lt; 5GB-file.log >> 6Mb-file-reduced.log</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Wondereful, Ruby took just few minutes to grep the regular exp string into a 5GB log file, and now I had to search orders
into this smaller reduced size intermediate file.</p>




<p>Thus, this saved us 3 days and did wonders in just half an hour.</p>




<p>Voila !!!</p>




<p>Credit for the one liner goes to <a href="http://axonflux.com/handy-ruby-one-liners-by-david-thomas">Garry Tan</a>, where I found this wonderful ruby command.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to use Angular-Datatables]]></title>
    <link href="http://blog.ashwani.co.in/blog/2018-07-03/how-to-use-angular-datatables/"/>
    <updated>2018-07-03T10:47:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2018-07-03/how-to-use-angular-datatables</id>
    <content type="html"><![CDATA[<p>This post is about quick demo of angularjs + datatables usage.
I am not gonna write too much theory, So here I will give only code snippet below.</p>




<!--more-->




<h4>References:</h4>




<p><a href="http://l-lin.github.io/angular-datatables">http://l-lin.github.io/angular-datatables</a><br/>
<a href="https://datatables.net">https://datatables.net</a></p>




<h3>Code:</h3>




<h4>index.html</h4>




<hr />




<script type="text/javascript" src="http://blog.ashwani.co.in/js/datatables.min.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/angular.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/angular-datatables.min.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/dataTables.tableTools.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/angular-datatables.tabletools.min.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/angular-datatables.bootstrap.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/dataTables.buttons.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/buttons.colVis.js"></script>




<script type="text/javascript" src="http://blog.ashwani.co.in/js/angular-datatables.buttons.js"></script>




<hr />




<h4>somejavascript.js</h4>




<p>myModule.controller('myDatatablesIntCtrl', function($scope,
    $rootScope, $http, DTOptionsBuilder, DTColumnBuilder, DTDefaultOptions) {</p>




<pre><code>var vm = this;
vm.dtOptions = DTOptionsBuilder.newOptions()
    .withDOM('&lt;"row"&lt;"col-md-8 col-sm-12"&lt;"inline-controls"l&gt;&gt;&lt;"col-md-4 col-sm-12"&lt;"pull-right"f&gt;B&gt;&gt;t&lt;"row"&lt;"col-md-4 col-sm-12"&lt;"inline-controls"T&gt;&gt;&lt;"col-md-4 col-sm-12"&lt;"inline-controls text-center"i&gt;&gt;&lt;"col-md-4 col-sm-12"p&gt;&gt;')
//.withDOM('Blfrtip')
.withDisplayLength(25)
//.withScroller()
//.withOption('deferRender', true)
//.withOption('scrollY', 200)
//.withOption('scrollX', '100%')
//.withOption('responsive', true)
//.withColVis()
//.withOption('order', [[3, 'desc']])
// Add Bootstrap compatibility
.withBootstrap()
.withBootstrapOptions({
        TableTools: {
            classes: {
                container: 'btn-group',
                buttons: {
                    normal: 'btn btn-lg btn-primary'
                }
            }
        },
        ColVis: {
            classes: {
                masterButton: 'btn btn-primary'
            }
        },
        pagination: {
            classes: {
                ul: 'pagination pagination-sm'
            }
        }

    })
.withOption('retrieve', true)

//.withButtons(['columnsToggle', {
//    extend: 'collection',
//    text: 'Hide columns',
//    buttons: ['columnsVisibility'],
//    visibility: false
//}])

// Add Table tools compatibility
.withTableTools('/plugins/datatables/copy_csv_xls_pdf.swf')
    .withTableToolsOption('sRowSelect', 'multi')
    .withTableToolsButtons([{
        'sExtends': 'copy',
        'sButtonText': 'Copy To Clipboard',
        'bSelectedOnly': true,
        'oSelectorOpts': {
            filter: 'applied',
            order: 'current'
        }
    }, {
        'sExtends': 'collection',
        'sButtonText': 'Export Data',
        'aButtons': [{
                'sExtends': 'xls',
                'sButtonText': 'XLS',
                'sFileName': '.xls',
                'bSelectedOnly': true,
                'oSelectorOpts': {
                    filter: 'applied',
                    order: 'current'
                }
                // 'fnMouseover': function ( nButton, oConfig, oFlash ) {
                //     alert( 'Mosue over' );
                // }
            }, {
                'sExtends': 'pdf',
                'bFooter': true,
                'bHeader': true,
                // 'mColumns': [0, 1, 2, 3, 4, 5, 6, 7],
                'sPdfOrientation': 'landscape',
                'sFileName': '.pdf',
                'bSelectedOnly': true,
                'oSelectorOpts': {
                    filter: 'applied',
                    order: 'current'
                }
            }, {
                'sExtends': 'csv',
                'sButtonText': 'CSV',
                'sFileName': '.csv',
                'bSelectedOnly': true,
                'oSelectorOpts': {
                    filter: 'applied',
                    order: 'current'
                }
            }
            // {
            //     'sExtends': 'text',
            //     'sButtonText': 'PNG',
            //     'bHeader': false,
            //     'bSelectedOnly': true,
            //     'oSelectorOpts': {
            //         'page': 'current'
            //     },
            //     'fnClick': function() {
            //         // Convert html table to canvas element
            //         html2canvas($(".active table"), {
            //             onrendered: function(canvas) {
            //                 var context = canvas.getContext("2d");
            //                 // Save canvas to file
            //                 canvas.toBlob(function(blob) {
            //                     saveAs(blob, '.png');
            //                 }); 
            //             }
            //         });
            //     }
            // }
        ]

    }]);

$scope.$on("InvokeDatatablesCtrl", function(event, args) {

    console.log('Table initialisation start: ' + new Date().getTime());

    var table = $('#mydatatable_id').DataTable();
    $('#mydatatable_id')
        .on('init.dt', function() {
            console.log('Table initialisation complete: ' + new Date().getTime());
            table.buttons().container().appendTo('#dt-buttons');
        }).dataTable();



    // console.log(args);
    // console.log("Inside myDatatablesIntCtrl");
    // $rootScope.alert = "Please wait...";
    //              $rootScope.error = "";
    // $.ajax({
    //  url : args.url,
    //  data : {},
    //  successFunction : function(data,status,headers,config)
    //  {

    //      $scope.tabs.datatableslist = data.data;  

    //  },
    // });

    // $resource(args.url).get().$promise.then(function(data)
    //      {

    //          if('code' in data &amp;&amp; data.code == "0")
    //          {
    //             $rootScope.alert = data.message;
    //             $rootScope.error = "";
    //              if('redirect' in data &amp;&amp; data.redirect != "")
    //              {
    //                  window.location = data.redirect;
    //              }

    //             $scope.tabs.viewrota.list = data.data;
    //             //console.log($scope.tabs.viewrota.list);

    //         }
    //          else if ('error' in data &amp;&amp; data.error != "")
    //          {
    //                  $rootScope.error = data.error;  
    //          }

    // });
});
</code></pre>




<p>});</p>




<h3>html or ctp file</h3>




<hr />




<div ng-show="showSummary == true" style="margin:0 auto;width:100%;overflow:auto;"  ng-controller="myDatatablesIntCtrl as mydatatable">

<table id="mydatatable_id" datatable="ng" dt-options="mydatatable.dtOptions" dt-column-defs="mydatatable.dtColumnDefs" dt-instance="mydatatable.dtInstance" class="table table-striped table-bordered table-condensed">
<thead>
<tr>
<th>Heading1</th>
<th>Heading2</th>
<th>Heading3</th>
</tr>
</thead>
<tbody>
<tr ng-repeat="incident in list">
<td>Column1</a></td>
<td>Column2</td>
<td>Column3</td>
</tr>
</tbody>
</table>
</div>




<hr />

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to use create ajax dropdown from database models in Rails]]></title>
    <link href="http://blog.ashwani.co.in/blog/2018-05-02/how-to-use-create-ajax-dropdown-from-database-models-in-rails/"/>
    <updated>2018-05-02T20:17:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2018-05-02/how-to-use-create-ajax-dropdown-from-database-models-in-rails</id>
    <content type="html"><![CDATA[<p>This post is about quick demo of Ajax based dropdown in rails.
The dropdown fetches the data from a collection in database.</p>




<!--more-->




<h3>index.html.erb</h3>




<hr />




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;div>
</span><span class='line'>&lt;%= f.collection_select :vertical, @verticals, :vertical, :vertical, {:prompt => "Select a Vertical"}, {:class => "dropdown_vertical btn btn-default dropdown-toggle"} %>
</span><span class='line'>
</span><span class='line'>&lt;%= f.collection_select :subVertical, @subVerticals, :subVertical, :subVertical, {:prompt => "Select a Sub Vertical"}, {:class => "dropdown_subVertical btn btn-default dropdown-toggle"} %>
</span><span class='line'>
</span><span class='line'>&lt;/div></span></code></pre></td></tr></table></div></figure></notextile></div>




<h3>custom.js</h3>




<hr />




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("#search_vertical").on('change', function(){
</span><span class='line'>var listitems = [];
</span><span class='line'>
</span><span class='line'>$.ajax({
</span><span class='line'>      url: "populate_subVerticals",
</span><span class='line'>      type: "GET",
</span><span class='line'>      data: {vertical_name: $(this).val()},
</span><span class='line'>      success: function(data) {
</span><span class='line'>      $("#search_subVertical").children().remove();
</span><span class='line'>      $("#search_subVertical").append('&lt;option value=>' + "Select a Sub Vertical" + '&lt;/option>');
</span><span class='line'>      $.each(data,function(key, value) 
</span><span class='line'>      {
</span><span class='line'>      listitems += '&lt;option value="' + value.subVertical + '">' + value.subVertical + '&lt;/option>';
</span><span class='line'>      });
</span><span class='line'>
</span><span class='line'>      $("#search_subVertical").append(listitems);
</span><span class='line'>
</span><span class='line'>      }
</span><span class='line'>  })
</span><span class='line'>});</span></code></pre></td></tr></table></div></figure></notextile></div>




<h3>Controller</h3>




<hr />




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def populate_subVerticals
</span><span class='line'>    vertical_name = params[:vertical_name]
</span><span class='line'>    @verticals = Vertical.where(:vertical => vertical_name).select("id","subVertical").all
</span><span class='line'>    respond_to do |format|
</span><span class='line'>      format.json { render json: @verticals }
</span><span class='line'>    end
</span><span class='line'>  end</span></code></pre></td></tr></table></div></figure></notextile></div>




<h3>routes.rb file</h3>




<hr />




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>get 'populate_subVerticals', to: 'verticals#populate_subVerticals'</span></code></pre></td></tr></table></div></figure></notextile></div>




<hr />




<p>That's it folks.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Commenting or Uncomment a block of text in Vi]]></title>
    <link href="http://blog.ashwani.co.in/blog/2018-03-09/commenting-or-uncomment-a-block-of-text-in-vi/"/>
    <updated>2018-03-09T10:43:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2018-03-09/commenting-or-uncomment-a-block-of-text-in-vi</id>
    <content type="html"><![CDATA[<p>Sometimes we do want to comment or uncomment a block of lines together in VI editor.
I struggle sometimes, so here are some tips.</p>




<!--more-->




<h3>For Uncommenting a block of text is almost the same:</h3>




<pre><code>Put your cursor on the first # character, press `CtrlV (or CtrlQ for gVim)`, and go down until the last commented line and press x, that will delete all the # characters vertically.
</code></pre>




<h3>For Commenting a block of text is almost the same:</h3>




<pre><code>* First, go to the first line you want to comment, press `Ctrl + v`. This will put the editor in the VISUAL BLOCK mode.
* Then using the arrow key and select until the last line and Now press `Shift + I` , which will put the editor in INSERT mode.
* Then press '#' character. This will add a hash to the first line.
* Then press Esc (give it a second), and it will insert a '#' character on all other selected lines.

For the stripped-down version of vim shipped with debian/ubuntu by default, type : s/^/# in the third step instead.
</code></pre>




<p>Reference: <a href="http://stackoverflow.com/a/1676690/1915916">Stackoverflow</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Check Connectivity to servers without login]]></title>
    <link href="http://blog.ashwani.co.in/blog/2018-02-25/check-connectivity-to-servers-without-login/"/>
    <updated>2018-02-25T22:57:31+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2018-02-25/check-connectivity-to-servers-without-login</id>
    <content type="html"><![CDATA[<p>There are times when you would want to check connectivity to your servers without actually login or SSH. You can use telnet on port 22.
But here are few other ways:</p>




<!-- more -->




<h3>Linux/Unix - Choose one of the below</h3>




<pre><code>
#! /bin/bash

rm good no_auth other
while read ip host ; do
    status=$(ssh -o BatchMode=yes -o ConnectTimeout=5 $ip echo ok 2&gt;&amp;1)
    if [[ $status == ok ]] ; then
        echo $ip $host &gt;&gt; good
    elif [[ $status == "Permission denied"* ]] ; then
        echo $ip $host $status &gt;&gt; no_auth
    else
        echo $ip $host $status &gt;&gt; other
    fi
done &lt; $1 
</code></pre>




<pre><code class="">
#! /bin/bash
while read ip host ; do
        echo quit | telnet $ip 22 2&gt;/dev/null | grep Connected &gt;&gt; resultsOfTelnetTests.txt

        # OR
        # $ ssh -q -o "BatchMode=yes" skinner "echo 2&gt;&amp;1" &amp;&amp; echo $host SSH_OK || echo $host SSH_NOK

        # OR
        # $ ssh -o BatchMode=yes -o ConnectTimeout=5 skinner echo ok 2&gt;&amp;1
done &lt; $1
</code></pre>




<h3>Windows</h3>




<pre><code>Script
=====

foreach($line in Get-Content .\serverList1.txt) {
      try{
            test-connection $line -Count 1 -Delay 2 -TTL 255 -BufferSize 256 -ThrottleLimit 32 | Select Address,IPv4Address,ResponseTime,BufferSize
      }catch [Exception] {
            echo .$line Not reachable.
      }
}


Serverlist1.txt contains the hostnames, one hostname in one line.
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IP Address GeoCoding and Plotting on map]]></title>
    <link href="http://blog.ashwani.co.in/blog/2016-01-23/ip-address-geocoding-and-plotting-on-map/"/>
    <updated>2016-01-23T21:49:37+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2016-01-23/ip-address-geocoding-and-plotting-on-map</id>
    <content type="html"><![CDATA[<p>Sometimes back I had setup ssh on raspberry pi and allowed to login from internet, obviously using the public key encyption.
After few days I noticed that lot of people/systems were trying to login and failing from various different IPs.
So I block them using Fail2ban. I am Not gonna talk about Fail2ban, as its completely vast topic on its own.</p>




<!--more-->




<p><a href="http://www.fail2ban.org/wiki/index.php/Main_Page">Fail2ban</a> : It provides a way to automatically protect virtual servers from malicious behavior.
The program works by scanning through log files and reacting to offending actions such as repeated failed login attempts.</p>




<p>Once blocked I wanted to see from where I was getting attacked the most. So I plotted them on map using some free apis.
Here is my fail2ban config for creating a file of all blocked IP addresses.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/pathToFail2ban/action.d/iptables-multiport.conf
</span><span class='line'>
</span><span class='line'>[Definition]
</span><span class='line'>
</span><span class='line'># Option:  actionstart
</span><span class='line'># Notes.:  command executed once at the start of Fail2Ban.
</span><span class='line'># Values:  CMD
</span><span class='line'>#
</span><span class='line'>
</span><span class='line'>actionstart = iptables -N fail2ban-&lt;name>
</span><span class='line'>              iptables -A fail2ban-&lt;name> -j RETURN
</span><span class='line'>              iptables -I &lt;chain> -p &lt;protocol> -m multiport --dports &lt;port> -j fail2ban-&lt;name>
</span><span class='line'>              cat /etc/fail2ban/ip.blacklist.persistban.&lt;name> | while read IP; do iptables -I fail2ban-&lt;name> 1 -s $IP -j DROP; done
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Option:  actionban
</span><span class='line'># Notes.:  command executed when banning an IP. Take care that the
</span><span class='line'>#          command is executed with Fail2Ban user rights.
</span><span class='line'># Tags:    &lt;ip>  IP address
</span><span class='line'>#          &lt;failures>  number of failures
</span><span class='line'>#          &lt;time>  unix timestamp of the ban time
</span><span class='line'># Values:  CMD
</span><span class='line'>#
</span><span class='line'>actionban = iptables -I fail2ban-&lt;name> 1 -s &lt;ip> -j DROP
</span><span class='line'>            echo &lt;ip> >> /etc/fail2ban/ip.blacklist.persistban.&lt;name>
</span><span class='line'>            echo &lt;ip> >> /pathToMysite/blocked_ipaddresses.txt</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>I used <a href="http://lab.abhinayrathore.com/ipmapper/">ipmapper</a> which uses google maps api for geocoding.</p>




<p>Here is my html code to plot those blocked IPs.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;html>
</span><span class='line'>&lt;head>
</span><span class='line'>&lt;script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js">&lt;/script>
</span><span class='line'>    &lt;script type="text/javascript" src="http://maps.google.com/maps/api/js?sensor=false">&lt;/script>
</span><span class='line'>    &lt;script type="text/javascript" src="ipmapper.js">&lt;/script>
</span><span class='line'>    &lt;meta name="viewport" content="initial-scale=1.0, user-scalable=no" />
</span><span class='line'>    &lt;style>
</span><span class='line'>      html, body, #map {
</span><span class='line'>        height: 100%;
</span><span class='line'>        margin: 0px;
</span><span class='line'>        padding: 0px;
</span><span class='line'>      }
</span><span class='line'>    &lt;/style>
</span><span class='line'>    &lt;script type="text/javascript">
</span><span class='line'>    $(function(){
</span><span class='line'>        try{
</span><span class='line'>                var useragent = navigator.userAgent;
</span><span class='line'>                var mapdiv = document.getElementById("map");
</span><span class='line'>                console.log(useragent.indexOf('iPhone'));
</span><span class='line'>                if (useragent.indexOf('iPhone') == -1 || useragent.indexOf('Android') == -1 ) {
</span><span class='line'>                        mapdiv.style.width = '100%';
</span><span class='line'>                        mapdiv.style.height = '100%';
</span><span class='line'>                } else {
</span><span class='line'>                        mapdiv.style.width = '600px';
</span><span class='line'>                        mapdiv.style.height = '800px';
</span><span class='line'>                }
</span><span class='line'>
</span><span class='line'>                IPMapper.initializeMap("map");
</span><span class='line'>
</span><span class='line'>                var file = "../data/blocked_ipaddresses.txt";
</span><span class='line'>                var ipArray = new Array();
</span><span class='line'>                $.get(file, function(data){
</span><span class='line'>                        ipArray = data.split('\n');
</span><span class='line'>                        //console.log("Raw array length is -" + ipArray.length);
</span><span class='line'>                        IPMapper.addIPArray(ipArray);
</span><span class='line'>                });
</span><span class='line'>
</span><span class='line'>        } catch(e){
</span><span class='line'>            //handle error
</span><span class='line'>        }
</span><span class='line'>    });
</span><span class='line'>    &lt;/script>
</span><span class='line'>&lt;/head>
</span><span class='line'>&lt;body>
</span><span class='line'>    &lt;div id="map" style="height: 800px;">&lt;/div>
</span><span class='line'>&lt;/body>
</span><span class='line'>&lt;/html></span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Here is the output plotted on the map... :)</p>




<p><img src="http://blog.ashwani.co.in/images/bot_attacks_on_pi.jpg" title="Bot attack image - not able to load pic." alt="alt " /></p>




<p>hmm.. lot of friendly visits from China and Russia... :)</p>




<p>Chow...</p>




<p><br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting up octopress blog once you lost the working env]]></title>
    <link href="http://blog.ashwani.co.in/blog/2016-01-17/setting-up-octopress-blog-once-you-lost-the-working-env/"/>
    <updated>2016-01-17T10:01:28+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2016-01-17/setting-up-octopress-blog-once-you-lost-the-working-env</id>
    <content type="html"><![CDATA[<p>Hi Guys,</p>




<p>So recently I wanted to revisit my blog after a long long break, and I realized that my working blogging environment broke and I wanted to setup again to be able to blog from both my personal laptop and any other laptop. But to my dismay, it was not that stright forward. Luckily, I had the source folder of my blog with me. It was quite a feat, Hence I thought of documenting it through this post.</p>




<!--more--> 




<h3>How Octopress works</h3>




<p>Octopress repositories have two branches, source and master. The <code>source</code> branch contains the files that are used to generate the blog and the <code>master</code> contains the blog itself.</p>




<p>When the local folders are initially configured according to the <a href="http://octopress.org/docs/setup/">Octopress Setup Guide</a>, the master branch is stored in a subfolder named _deploy. Since the folder name begins with an underscore, it is ignored when you git push origin source. Instead, the master branch (which contains your blog posts) gets updated when you rake deploy.</p>




<h3>Clone your blog to the new machine</h3>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git clone -b source git@github.com:username/username.github.com.git Local_octopress
</span><span class='line'>$ cd Local_octopress
</span><span class='line'>$ git clone git@github.com:username/username.github.com.git _deploy 
</span><span class='line'>$ gem install bundler
</span><span class='line'>$ rbenv rehash    # If you use rbenv, rehash to be able to run the bundle command
</span><span class='line'>
</span><span class='line'>$ bundle install
</span><span class='line'>
</span><span class='line'>$ rake setup_github_pages
</span><span class='line'>
</span><span class='line'>It will prompt you for your repository URL.
</span><span class='line'>Enter the read/write url for your repository
</span><span class='line'>(For example, 'git@github.com:your_username/your_username.github.com)
</span><span class='line'>Thats you setup with a new local copy of your Octopress blog.</span></code></pre></td></tr></table></div></figure></notextile></div>




<h3>Pushing changes from two different machines</h3>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>If you want to blog from more than one computer, you need to make sure that you push everything before switching computers. 
</span><span class='line'>From the first machine do the following whenever youve made changes:
</span><span class='line'>
</span><span class='line'>$ rake generate
</span><span class='line'>$ git add .
</span><span class='line'>$ git commit -am "Some comment here." 
</span><span class='line'>$ git push origin source  # update the remote source branch 
</span><span class='line'>$ rake deploy             # update the remote master branch
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Then on the other machine, you need to pull those changes.
</span><span class='line'>
</span><span class='line'>$ cd octopress
</span><span class='line'>$ git pull origin source  # update the local source branch
</span><span class='line'>$ cd ./_deploy
</span><span class='line'>$ git pull origin master  # update the local master branch</span></code></pre></td></tr></table></div></figure></notextile></div>




<h3>Octopress 2.0</h3>




<p>If you were returning to blogging after so long, chances are that there were many things <a href="https://github.com/imathis/octopress/blob/master/CHANGELOG.markdown">changed</a>.</p>




<ol>
<li>Rubypants is removed.</li>
<li>Include Code Tag lets you embed external code snippets from your file system and adds a download link</li>
<li>Pullquote Tag Generate beautiful semantic pullquotes (no double data) based on Maykel Loomans's technique</li>
<li>Category Generator gives you archive pages for each category</li>
<li>Sitemap.xml Generator for search engines</li>
</ol>




<p>etc. etc.</p>




<p>I got so many errors once I checked out a new version of Octopress. It was not supporting many of my old plugins, So I got rid of some, and I updated some.</p>




<h3>Errors</h3>




<p>One error I got was in date.rb of <a href="http://feedjira.com/">feedjira(formerly feedzira)</a> plugin.
The error message said:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>jekyll 2.1.1 undefined method `deep_merge'</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>so I replaced deep_merge</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def to_liquid
</span><span class='line'>          date_format = self.site.config['date_format']
</span><span class='line'>      self.data.deep_merge({
</span><span class='line'>          "title"             => self.data['title'] || self.slug.split('-').select {|w| w.capitalize! || w }.join(' '),
</span><span class='line'>          "url"               => self.url,
</span><span class='line'>          "date"              => self.date,
</span><span class='line'>          # Monkey patch
</span><span class='line'>          "date_formatted"    => format_date(self.date, date_format),
</span><span class='line'>          "updated_formatted" => self.data.has_key?('updated') ? format_date(self.data['updated'], date_format) : nil,
</span><span class='line'>          "id"                => self.id,
</span><span class='line'>          "categories"        => self.categories,
</span><span class='line'>          "next"              => self.next,
</span><span class='line'>          "previous"          => self.previous,
</span><span class='line'>          "tags"              => self.tags,
</span><span class='line'>          "content"           => self.content })
</span><span class='line'>  end</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>with the following:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def to_liquid(attrs = nil)
</span><span class='line'>      date_format = self.site.config['date_format']
</span><span class='line'>      new_datas = {
</span><span class='line'>        "title"             => self.data['title'] || self.slug.split('-').select {|w| w.capitalize! || w }.join(' '),
</span><span class='line'>        "url"               => self.url,
</span><span class='line'>        "date"              => self.date,
</span><span class='line'>        # Monkey patch
</span><span class='line'>        "date_formatted"    => format_date(self.date, date_format),
</span><span class='line'>        "updated_formatted" => self.data.has_key?('updated') ? format_date(self.data['updated'], date_format) : nil,
</span><span class='line'>        "id"                => self.id,
</span><span class='line'>        "categories"        => self.categories,
</span><span class='line'>        "next"              => self.next,
</span><span class='line'>        "previous"          => self.previous,
</span><span class='line'>        "tags"              => self.tags,
</span><span class='line'>        "content"           => self.content }
</span><span class='line'>     
</span><span class='line'>      Utils.deep_merge_hashes(self.data, new_datas)
</span><span class='line'>    end</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Notice the use of deep_merge_hashes above.</p>




<p>Another error was <code>Updates were rejected because the tip of your current branch is behind</code> when I executed "bundle exec rake gen_deploy"</p>




<p>The reason is that Octopress only does a push to the <code>master</code> branch and not a pull. To resolve this, do this:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ cd _deploy
</span><span class='line'>$$ git push origin master -f   # hope this solves the problem, move to next command
</span><span class='line'>$$ cd ..
</span><span class='line'>$$ bundle exec rake gen_deploy</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Another error was in installing curl on windows. So I had to refer <a href="https://github.com/taf2/curb/issues/37">this</a>
And install curb manually.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>C:\Users\AshwaniK> gem install curb  -v '0.7.18' -- --with-curl-lib=C:\libcurl\bin --with-curl-include=C:\libcurl\include
</span><span class='line'>Temporarily enhancing PATH to include DevKit...
</span><span class='line'>Building native extensions with: '--with-curl-lib=C:\libcurl\bin --with-curl-include=C:\libcurl\include'
</span><span class='line'>This could take a while...
</span><span class='line'>Successfully installed curb-0.7.18
</span><span class='line'>Installing ri documentation for curb-0.7.18
</span><span class='line'>1 gem installed</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Reference Commands:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd octopress
</span><span class='line'>bundle exec rake new_post["title"]
</span><span class='line'>bundle exec rake preview
</span><span class='line'>bundle exec rake generate
</span><span class='line'>
</span><span class='line'>bundle exec rake deploy
</span><span class='line'>
</span><span class='line'>git add .
</span><span class='line'>git commit -m 'site updated'
</span><span class='line'>git push origin source</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>There were other errors which I somehow resolved.</p>




<p>Hope this helps someone.  I might need this again, So I am keeping a refrence.</p>




<p>Thats all folks. Chow.</p>




<p>Credits to: <br/>
1.  <a href="http://stackoverflow.com/questions/15864872/trouble-with-cloning-octopress-blog-on-other-laptops-computers-conflict-isseue">Trouble-with-cloning-octopress-blog-on-other-laptops</a>   <br/>
2.  <a href="http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/">Clone Your Octopress to Blog From Two Places.</a>   <br/>
3.  <a href="http://blog.mohitkanwal.com/blog/2014/03/26/blogging-with-octopress-from-2-computers/">Blogging-with-octopress-from-2-computers/</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MQTT, All you need to get started]]></title>
    <link href="http://blog.ashwani.co.in/blog/2015-03-10/mqtt-all-you-need-to-get-started/"/>
    <updated>2015-03-10T08:00:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2015-03-10/mqtt-all-you-need-to-get-started</id>
    <content type="html"><![CDATA[<p>So there are numerous post out there for MQTT implementation. I recently did a POC at work, and I wanted to keep a list of things I need to know if I wanted to return or do more with MQTT.
Hence this post.</p>




<h3><a href="http://mqtt.org/">MQTT</a></h3>




<p>MQTT is a machine-to-machine (M2M)/"Internet of Things" connectivity protocol. It was designed as an extremely</p>




<!--more-->  




<p>lightweight publish/subscribe messaging transport. It is useful for connections with remote locations where a small code footprint is required and/or network bandwidth is at a premium.</p>




<h4>Demo Architecture</h4>




<p><img src="http://blog.ashwani.co.in/assets/MQTT_Arch.jpg" title="MQTT Architecture" alt="Cannot Display Architecture diagram, open this link /assets/MQTT_Arch.jpg" /></p>




<h2>Installing software</h2>




<h4>Installing Node.JS</h4>




<hr />




<p>Please follow the <a href="http://joshondesign.com/2013/10/23/noderpi">instructions</a> to install nodejs.
After that, install some modules using the Node Package Manager:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Command for node modules </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>npm install -g mqtt url request</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>If you want to debug or auto-reload of the script, also install nodemon:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Command for nodemon </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>npm install -g nodemon</span></code></pre></td></tr></table></div></figure></notextile></div>




<p><br/><br/>
<br/></p>




<h4>Installing MQTT Broker - Mosquitto (or Checkout <a href="http://www.hivemq.com/how-to-get-started-with-mqtt/">HiveMQ</a>)</h4>




<hr />




<p>Source: <a href="http://jpmens.net/2013/09/01/installing-mosquitto-on-a-raspberry-pi/">http://jpmens.net/2013/09/01/installing-mosquitto-on-a-raspberry-pi/</a></p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Commands for mosquitto </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -O http://repo.mosquitto.org/debian/mosquitto-repo.gpg.key     
</span><span class='line'>sudo apt-key add mosquitto-repo.gpg.key   
</span><span class='line'>rm mosquitto-repo.gpg.key 
</span><span class='line'>cd /etc/apt/sources.list.d/   
</span><span class='line'>sudo curl -O http://repo.mosquitto.org/debian/mosquitto-repo.list 
</span><span class='line'>sudo apt-get update</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Now go ahead and install Mosquitto proper. There are three packages:</p>




<p>-Mosquitto is the MQTT broker (i.e. server)   <br/>
-mosquitto-clients are the command-line clients, which I recommend you install  <br/>
-python-mosquitto are the Python bindings, which I also think you should install all three packages together require about 665Kb of space, which we can easily afford even on the tiny Pi.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Commands for mosquitto and client installations </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt-get install mosquitto mosquitto-clients python-mosquitto</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>Mosquitto/'s default configuration means it is set up to not use username/password authentication and accepts all connections on port 1883. It also comes with two clients, mosquitto_pub and mosquitto_sub, the latter of which will be useful when you are debugging your applications. Running:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Command for subscribing </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mosquitto_sub -t "#" -v</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>will dump all new messages to the broker. Remember the quotes around the topic, especially with the "#" wildcard on Unix as, unquoted or unescaped, that marks the start of a comment and would see the rest of the command discarded. If you leave that command running and, in another window, run</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Command for publishing </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>'mosquitto_pub -t "mosquittodemo/test" -m "Hi"'</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>then you should see the mosquitto_sub session list the message.</p>




<p><br />
<br /></p>




<h4>Installing MQTT Client - MQTTWarn</h4>




<hr />




<p>This program subscribes to any number of MQTT topics (which may include wildcards) and publishes received payloads to one or more notification services, including support for notifying more than one distinct service for the same message.</p>




<p>For example, you may wish to notify via e-mail and to Pushover of an alarm published as text to the MQTT topic <code>home/monitoring/+</code>.</p>




<p>Full Info <a href="http://jpmens.net/2014/02/17/introducing-mqttwarn-a-pluggable-mqtt-notifier/">here</a></p>




<h4>Requirements</h4>




<p>You'll need at least the following components:</p>




<p>-Python 2.x (tested with 2.6 and 2.7)  <br/>
-An MQTT broker (e.g. Mosquitto)   <br/>
-The Paho Python module: pip install paho-mqtt</p>




<h4>Installation</h4>




<p>-Clone <a href="https://github.com/jpmens/mqttwarn.git">this</a> repository into a fresh directory.</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Clone the repo </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jpmens/mqttwarn.git</span></code></pre></td></tr></table></div></figure></notextile></div>




<p>
-Copy mqttwarn.ini.sample to mqttwarn.ini and edit to your taste   <br/>
-Install the prerequisite Python modules for the services you want to use   <br/>
-Launch mqttwarn.py</p>




<p><br /></p>




<h3>MQTT Android Client</h3>




<hr />




<h4>Android Service</h4>




<p>The Paho Android Service is an interface to the Paho Java MQTT client library that provides a long running service for handling sending and receiving messages on behalf of Android client applications when the applications main Activity may not be running.</p>




<p>The Paho Android Service provides an asynchronous API</p>




<h4>Source:</h4>




<p><a href="http://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.java.git/">http://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.java.git/</a></p>




<p>Check out Paho project <a href="https://eclipse.org/paho/clients/android/">here</a></p>




<p>All you need to get started is:</p>




<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Code for creating client and publishing a message </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>client = new MqttClient("tcp://ipAddressofBroker:1883", "pahomqttpublish1");    
</span><span class='line'>client.connect();    
</span><span class='line'>MqttMessage message = new MqttMessage();     
</span><span class='line'>message.setPayload("A single message".getBytes());    
</span><span class='line'>client.publish("home/monitoring/+", message);    
</span><span class='line'>client.disconnect();</span></code></pre></td></tr></table></div></figure></notextile></div>




<p><br /></p>




<h4>Test Broker Setup</h4>




<hr />




<p>To test your Broker setup you can install <a href="https://play.google.com/store/apps/details?id=at.tripwire.mqtt.client">MyMQTT</a> from google play.</p>




<p>In few days I am gonna write myself a post about Google Cloud Notification service (GCM). The easiet notification service for Android notifications.</p>




<p><br/>
That's all folks.  Have Fun.</p>




<p><br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HeartBleed Bug]]></title>
    <link href="http://blog.ashwani.co.in/blog/2014-04-11/openssl-heartbleed/"/>
    <updated>2014-04-11T08:13:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2014-04-11/openssl-heartbleed</id>
    <content type="html"><![CDATA[<p>Hey Guys,</p>




<p>Few days ago, A mother of all bugs in internet world was discovered, a new vulnerability <a href="http://blog.cloudflare.com/staying-ahead-of-openssl-vulnerabilities">CVE-2014-0160</a> was announced in OpenSSL 1.0.1.</p>




<p>An encryption flaw called the <a href="http://heartbleed.com/">Heartbleed bug</a> is already being called one of the biggest security threats the Internet has ever seen.</p>




<!--more-->




<p><img class="left_aligned_image" src="http://blog.ashwani.co.in/assets/heartbleed.svg" width="350" height="350" title="Heartbleed SVG" alt="HeartBleed SVG image"></p>




<p>As Bruce Schneier, a renowned security expert, said in a <a href="https://www.schneier.com/blog/archives/2014/04/heartbleed.html">blog post</a> on Wednesday:</p>




<h4>"Heartbleed is a catastrophic bug . . . on a scale of one to 10, it is an 11."</h4>




<p>According the <a href="http://heartbleed.com/">Heartbleed website</a> dedicated for this bug:</p>




<p>The Heartbleed bug allows anyone on the Internet to read the memory of the systems protected by the vulnerable versions of the OpenSSL software.
This compromises the secret keys used to identify the service providers and to encrypt the traffic, the names and passwords of the users and the actual content. This allows attackers to eavesdrop on communications, steal data directly from the services and users and to impersonate services and users.</p>




<p><br/>
<br/>
<br/>
When an attacker can reach a vulnerable service he can abuse the TLS heartbeat extension to retrieve arbitrary chunks of memory by exploiting a
missing bounds check. This can lead to disclosure of your private keys, resident session keys and other key material as well as all volatile
memory contents of the server process like passwords, transmitted user data (e.g. web content) as well as other potentially confidential information.</p>




<p>An attacker can grab 64K of memory from a server. The attack leaves no trace, multiple times to grab a different random 64K of memory.  <br/>
This means that anything in memory , like SSL private keys, user keys,passwords , anything is vulnerable. <br/>
And you have to assume that it is all compromised. All of it.</p>




<p><br/>
<br/>
<img src="http://imgs.xkcd.com/comics/heartbleed_explanation.png" title="xkcd Heartbleed cartoon explanation" alt="HeartBleed xkcd cartoon"></p>




<p><br/>
<br/>
After being out there in wild for almost around 2 years, The heartbleed bug was <a href="https://www.openssl.org/news/secadv_20140407.txt">fixed</a> by openssl community on 7th April 2014.</p>




<p>Users are encouraged who are running a server that uses OpenSSL to upgrade to version 1.0.1g to be protected from this vulnerability.
For previous versions of OpenSSL, re-compiling with the OPENSSL_NO_HEARTBEATS flag enabled will protect against this vulnerability.
OpenSSL 1.0.2 will be fixed in 1.0.2-beta2.</p>




<p>You must also assume that at least your used server keys are compromised and therefore must be replaced by newly generated ones. Simply renewing
existing certificates is not sufficient! - Please generate NEW keys with at least 2048 bit RSA or stronger!</p>




<p><br/>
<br/></p>




<h4>Here are a few tips and resources you may find helpful:</h4>




<ul>
<li>Ensure that you upgrade your system to a fixed OpenSSL version (1.0.1g or above).</li>
<li>You can also test your website to see if its vulnerable to attack  <a href="http://filippo.io/Heartbleed/">http://filippo.io/Heartbleed/</a>  and  <a href="http://possible.lv/tools/hb/">http://possible.lv/tools/hb/</a></li>
<li>Only then create new keys for your certificates.</li>
<li>Revoke all certificates, which may be affected.</li>
<li>Check what services you have used that may have been affected within the last two years.</li>
<li>Wait until you think that those environments got fixed.</li>
<li>Then (and only then) change your credentials for those services. If you do it too early, i.e. before the sites got fixed, your data may be leaked, again. So be careful when you do this.</li>
<li>Mashable have compiled <a href="http://mashable.com/2014/04/09/heartbleed-bug-websites-affected/">list</a> of which websites and organizations are vulnerable  from banks to social media sites.</li>
</ul>




<p><br/>
An (incomplete) list of commonly used software which include or link to OpenSSL can be found <a href="https://www.openssl.org/related/apps.html">here</a>.</p>




<p><br/></p>




<h4>Sources:</h4>




<p><a href="http://heartbleed.com/">heartbleed.com</a> <br/>
<a href="http://filippo.io/Heartbleed/">Test for vulverabilty</a> and  <a href="http://possible.lv/tools/hb/">Test for vulverabilty - 2</a> <br/>
<a href="http://www.cnet.com/uk/news/heartbleed-bug-what-you-need-to-know-faq/">What you need to know - FAQ</a>
<a href="http://blog.cryptographyengineering.com/2014/04/attack-of-week-openssl-heartbleed.html">attack-of-week-openssl-heartbleed</a>  <br/>
<a href="http://blog.existentialize.com/diagnosis-of-the-openssl-heartbleed-bug.html">diagnosis-of-the-openssl-heartbleed-bug</a>  <br/>
<a href="http://security.stackexchange.com/questions/55116/how-exactly-does-the-openssl-tls-heartbeat-heartbleed-exploit-work">A simple explanation at security.stackexchange.com, on how-exactly-does-the-openssl-tls-heartbeat-heartbleed-exploit-work</a>  <br/>
<a href="http://news.netcraft.com/archives/2014/04/08/half-a-million-widely-trusted-websites-vulnerable-to-heartbleed-bug.html">half-a-million-widely-trusted-websites-vulnerable-to-heartbleed-bug</a>  <br/>
<a href="http://arstechnica.com/security/2014/04/critical-crypto-bug-exposes-yahoo-mail-passwords-russian-roulette-style/">critical-crypto-bug-exposes-yahoo-mail-passwords-russian-roulette-style</a>  <br/>
<a href="https://www.schneier.com/blog/archives/2014/04/heartbleed.html">A renowned security expert, schneier Blog</a> <br/>
<a href="https://hackerone.com/reports/6626">Neel Mehta donates Heartbleed bounty to Freedom of the Press Foundation</a>  <br/>
<a href="https://news.ycombinator.com/item?id=7548991">Hacker News Thread</a>  <br/>
<a href="http://www.cnet.com/uk/news/which-sites-have-patched-the-heartbleed-bug">Sites which have patched the Bug</a></p>




<p><br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Long Live WindowsXp/Run XP in a Virtual Box for free]]></title>
    <link href="http://blog.ashwani.co.in/blog/2014-03-07/long-live-windowsxp/"/>
    <updated>2014-03-07T23:25:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2014-03-07/long-live-windowsxp</id>
    <content type="html"><![CDATA[<p>The long loved , super user friendly Operating System's Life is going to see the last light in few days. <br/>
Windows XP, the cornerstone of most PC users for the past 10+ years, is being officially phased out.</p>




<!--more-->




<iframe class="restricted" scrolling="no" src="http://support.microsoft.com/lifecycle/?LN=en-ie&c2=1173#tableContainer" width=105% height="370" frameborder="1"></iframe>




<p>We all loved Windows XP. Although you can still run XP on your PCs , laptops but at your own risks.
Microsoft has publicly stated that no new patches will be released for the OS after April 2014 (outside of very critical security flaws found.)</p>




<p>If in case you love Windows-7 more , but wanna use Windows-XP as well , then read on..</p>




<h4>Running Windows XP in a Virtual Box for free</h4>




<h5>Follow the steps:</h5>




<ol>
<li>Download <a href="http://www.microsoft.com/windows/virtual-pc/download.aspx">Windows XP Mode</a> (WindowsXPMode_en-us.exe | MD5: bf3726d684d3acb98185665123c9efcf)</li>
<li>Extract xpm from WindowsXPMode_en-us.exe with a file archiver 7-Zip etc.</li>
<li>Add .rar extension to xpm</li>
<li>Extract VirtualXPVHD from xpm.rar</li>
<li>Add .vdi extension to VirtualXPVHD</li>
<li>Create new machine in VirtualBox, specifying VirtualXPVHD.vdi as the hard disk</li>
<li>Once initial setup is complete, uninstall Virtual PC Integration Components from Add/Remove Control Panel</li>
<li>Install Guest Additions (Devices > Install Guest Additions...)</li>
</ol>




<p>Once you start the Virtual Box, you will be asked to activate windows-xp. But wait, I do not have activation code, I thought this process was for free.
Hold on, don't jump your horses..Follow the next steps.</p>




<ol>
<li>Shut down virtual machine</li>
<li>Download pcbios.bin (MD5: 12ccdc652b30c6d1e307c6f7deff5d24) from <a href="http://www.vmlite.com/index.php?option=com_kunena&amp;Itemid=158&amp;func=view&amp;catid=9&amp;id=6706&amp;limit=6&amp;limitstart=12#8420">VMLite</a> and copy to a directory on host computer (e.g., C:\vm)</li>
<li>Run the command: "C:\Program Files\Oracle\VirtualBox\VBoxMange.exe" setextradata vm-name "VBoxInternal/Devices/pcbios/0/Config/BiosRom" "c:\vm\pcbios.bin"</li>
</ol>




<p><br/></p>




<h4>Notes:</h4>




<p class="mynotice">While a virtual machine created in this manner should run under any OS X, Linux, or Windows host, running under anything but Windows 7 Professional, Enterprise, 
or Ultimate would apparently violate the Windows XP Mode EULA:
You may install, use, access, display and run one copy of the Software in a single virtual machine on a single computer, such as a workstation, terminal or other device ("Workstation Computer"), 
that contains a licensed copy of Windows 7 Professional, Enterprise or Ultimate edition. Virtualization software is required to use the Software on the Workstation Computer ... 
If you are using the Software with a properly licensed copy of Windows 7 Professional, Enterprise or Ultimate, activation of the Software is not required.
</p>




<p>More Info on this can be found <a href="http://social.technet.microsoft.com/Forums/windows/en-US/8b1bfa74-15e0-4ce2-8612-f6eaf2cf25ab/is-it-ok-to-use-xp-mode-vhd-in-virtualbox-without-a-license-using-vmlite-xp-mode-plugin?forum=w7itprovirt">here</a></p>




<h5>Sources:</h5>




<p><a href="http://www.technibble.com/windows-xp-support-ends-in-april-2014-what-technicians-need-to-know/">www.technibble.com</a>  <br/>
<a href="http://tinyapps.org/blog/windows/201210210700_xp_mode_virtualbox.html">tinyapps</a></p>




<p><br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BroPages a readable supplement to man pages]]></title>
    <link href="http://blog.ashwani.co.in/blog/2014-01-28/bropages-a-readable-supplement-to-man-pages/"/>
    <updated>2014-01-28T08:31:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2014-01-28/bropages-a-readable-supplement-to-man-pages</id>
    <content type="html"><![CDATA[<p>A little while ago , I shared an amazing tool with all of you , <a href="http://blog.ashwani.co.in/blog/2013-12-03/shell-commands-explained-like-never-before/">Explain Shell</a>.</p>




<p>Today I came across another good resource for the *nix programmers. And it's called , <a href="http://bropages.org/">bro pages</a>.
Just like man pages,but with readable examples to the commands.</p>




<!--more-->




<p>Have a look at the following example command from your terminal, after you install bro pages.</p>




<pre>
        Command#> bro tar
        # Create a tar archive
        tar -cf archive.tar file1 file2 ... fileN
        
        # Create a tar gzipp'd archive
        tar -zcf archive.tar.gz file1 file2 ... fileN
        
        # Create multi-part tar archives from a directory
        tar cf - /path/to/directory|split -b<max_size_of_part>M - archive.tar
        
        # Extract all files from a tar archive
        tar -xf archive.tar
        
        # Extract all files from a tar gzipped archive
        tar -zxf archive.tar.gz
        
        # Extract one file from a tar archive
        tar -xf archive.tar the_one_file
        
        # Lists all files in a tar archive
        tar -tf archive.tar
</pre>




<p>You can find more examples <a href="http://bropages.org/browse">here</a>.</p>




<p>Or better why don't you install it and give a try.
Installation is super easy with just one command:
    "gem install bropages"</p>




<p>You need Ruby 1.8.7+ installed on your machine though for this to work.</p>




<p>You can add your own examples of commands to bro pages by using:
    bro add curl</p>




<p>You can vote up and down for the commands examples by using:
    bro thanks      to upvote (2)
    bro ...no       to downvote (0)
This way, people will see the most rates command examples first with highest votes.</p>




<p>I personally feel, this is a good idea. You should also check it out.</p>




<p>That all folks.</p>




<p>Thanks for reading this far.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shell Commands explained like never before]]></title>
    <link href="http://blog.ashwani.co.in/blog/2013-12-03/shell-commands-explained-like-never-before/"/>
    <updated>2013-12-03T21:27:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2013-12-03/shell-commands-explained-like-never-before</id>
    <content type="html"><![CDATA[<p>Idan Kamara has came up with a very intriguing and useful tool <a href="http://explainshell.com/">Explain Shell</a>. He has created a cool web app which explains any Shell Command visually.
You give a shell command and it will tell you what the each option does.  This makes understanding the complex looking commands very easier.</p>




<!--more-->




<p><img src="http://blog.ashwani.co.in/assets/ExplainShell-1.JPG" width="800" height="600" title="Explain Shell" alt="Explain Shell Image"></p>




<p><br /></p>




<hr />




<p>It becomes a bit tedious for a very long complex command like <a href="http://explainshell.com/explain?cmd=ps+x+-o++%22%25r+%25c+%22+|+grep+%22webLauncher.sh%22+|+awk+-F%27+%27+%27{print+%241}%27+|+xargs+-I+%25+%2Fbin%2Fkill+-TERM+--+-%25">this</a> though.
But I would overlook that given the awesomeness of this tool and the fact that you can click on the commands to get the MAN pages helps.</p>




<p>For e.g. If you click on tar as in the following screenshot, you will get the MAN pages of tar.
<img src="http://blog.ashwani.co.in/assets/ExplainShell-2.JPG" width="800" height="600" title="Explain Shell" alt="Explain Shell tar command Image"></p>




<hr />




<p><img src="http://blog.ashwani.co.in/assets/ExplainShell-3.JPG" width="800" height="600" title="Explain Shell" alt="Explain Shell Man Page Image"></p>




<hr />




<p><strong>Positives</strong></p>




<hr />




<ol>
<li>Its Open-source. Find the source code <a href="https://github.com/idank/explainshell">here</a></li>
<li>It has simple beautiful interface.</li>
<li>You can log issues <a href="https://github.com/idank/explainshell/issues">here</a></li>
</ol>




<hr />




<p><strong>Negatives</strong></p>




<hr />




<p>I don't Mind any.  :)</p>




<p>I hope this would help many of us.  Kudos and my best wishes to the developer. <br/>
<br />
-Ashwani Kumar Via <a href="https://news.ycombinator.com/item?id=6834791">HackerNews</a><br/>
<br /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Instant Nokogiri - Book Review]]></title>
    <link href="http://blog.ashwani.co.in/blog/2013-11-10/instant-nokogiri-book-review/"/>
    <updated>2013-11-10T12:39:00+00:00</updated>
    <id>http://blog.ashwani.co.in/blog/2013-11-10/instant-nokogiri-book-review</id>
    <content type="html"><![CDATA[<p>Hello Guys, Recently I was requested to review a book by <a href="http://hunterpowers.com/">Hunter Powers</a>.
The book is titled as "<a href="http://www.packtpub.com/utilize-information-available-on-internet-using-Nokogiri/book">Instant Nokogiri</a>'.</p>




<p>So here are my unbiased thought on the same:</p>




<p><a href="http://nokogiri.org/">Nokogiri</a> - is an HTML, XML, SAX, &amp; Reader <!--more--> parser with the ability to search documents via XPath or CSS3 selectors and much more</p>




<p><a href="http://www.packtpub.com/utilize-information-available-on-internet-using-Nokogiri/book">
<img class="left_aligned_image" src="http://blog.ashwani.co.in/assets/Nokogiri.JPG" width="350" height="350" title="Instant Nokogiri" alt="Instant Nokogiri image">
</a></p>




<p><strong>This book is in its simplest and easiest form, explains the basics of Nokogiri in a layman's language.<br/>
A definite read for all those who love simplicity and awesomeness of ruby language.</strong></p>




<p><strong>Book is in interest of those new-comers who would like to learn scraping data from 'websites/other sources' which does not provide a developer API.</strong></p>




<p>It does not have any fancy graphics, no vague examples etc. It just dives into the real subject , which is what a beginner (or expert for that matter)
would require to get started or master Nokogiri.</p>




<p>With very subtle examples of data scraping and clear understanding, the author makes a newbee feel like they already
know how Nokogiri works.</p>




<p>The section "Top 13 features you need to know about" clearly explains some of the not known features of Nokogiri.
My favorite parts are about "Spoofing browser agents"  and "Mechanize".</p>




<p>All in all this is perfect book for beginners. But if you are an expert ruby developer and use nokogiri extensively,
this book may not be for you.</p>




<p><strong><u>For a first time user, I definitely recommend this book.</u></strong></p>




<p>You can get a copy from these places:</p>




<ol>
<li><a href="http://www.packtpub.com/utilize-information-available-on-internet-using-Nokogiri/book">packtpub</a></li>
<li><a href="http://www.amazon.co.uk/gp/product/B00ESX180G">Amazon.co.uk</a></li>
</ol>




<p><br/><br/></p>




<h3>Some Nokogiri Info:</h3>




<h4>Install</h4>




<pre><code>sudo gem install nokogiri 
</code></pre>




<h4>Contribute</h4>




<pre><code>http://github.com/sparklemotion/nokogiri
</code></pre>




<p><br/>
<br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reclaim that important diskspace with New Windows Update Cleanup]]></title>
    <link href="http://blog.ashwani.co.in/blog/2013-10-14/reclaim-that-important-diskspace-with-new-windows-update-cleanup/"/>
    <updated>2013-10-14T08:35:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2013-10-14/reclaim-that-important-diskspace-with-new-windows-update-cleanup</id>
    <content type="html"><![CDATA[<p>Yippee !</p>




<p>Finally Microsoft has released a very important update package.</p>




<p>Remember, how we used to despise the windows updates and security patches eating up our diskspace. And many a times, we even used to skip
the update with the feeling of satisfaction (just saved a lot of diskspace) <!--more--> and dissatisfaction (what if it included a critical patch).</p>




<p>Well, Not anymore! We don't have to be in dilemma anymore. Since, Microsoft has released a very important update this time, with which we can cleanup the
otherwise outdated windows update files.</p>




<p>This release is for Windows 7 SP1 machines, KB <a href="http://support.microsoft.com/kb/2852386">2852386</a> adds the ability to cleanup all the obsolete updates in the WinSxS folder.</p>




<blockquote><p>Windows Updates can be terrible space hogs. Windows saves every security update and hotfixeven if <br/>they are superseded by new updatesin the WinSxS directory. You cannot just manually delete everything in that folder,because some files are needed just in case a system file gets corrupted or you need to roll back a Windows Update. - Life Hacker</p></blockquote>




<p>A new  recommended update was released. It can be found <a href="http://support.microsoft.com/kb/2852386">Here</a>.</p>




<p><b>Note: that this is categorized as an important update.
This means its not a critical security update which means it may not be automatically installed or deployed depending on your
Windows Update settings, WSUS settings, or other 3rd party patch management software settings.</b></p>




<p>Via - <a href="http://blogs.technet.com/b/askpfeplat/archive/2013/10/07/breaking-news-reduce-the-size-of-the-winsxs-directory-and-free-up-disk-space-with-a-new-update-for-windows-7-sp1-clients.aspx">Breaking News! Reduce the size of the WinSxS Directory and Free up Disk Space with a New Update for Windows 7 SP1 Clients</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Free Feedback Form using Github]]></title>
    <link href="http://blog.ashwani.co.in/blog/2013-09-30/free-feedback-form-using-github/"/>
    <updated>2013-09-30T06:24:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2013-09-30/free-feedback-form-using-github</id>
    <content type="html"><![CDATA[<p>Hi Friends,<br/>
I could not write anything for last few weeks, had been busy with usual chores and a weekend project with my brother(about which you will come to know, when we bring it to a better shape).</p>




<p>But I am back , and would try to be consistent.</p>




<p>Promise.</p>




<!--more-->




<p>This post is to let you know a little trick that I am gonna start following, many of you may already be following it.</p>




<p>Ever wanted to have your users contact you for random issues, or just let them contact you for their queries,
and you have to create a contact_us or feedback page.  Well I would like to share with you , what I had found,
a neat little trick which uses github repo as a feedback page.</p>




<p>Go ahead have a look, click on the button and leave me a feedback or queries or questions, I would try to answer them as quickly as I can.</p>




<p><a class="btn btn-mini btn-info" href="https://github.com/TheAshwaniK/Feedback/issues/new" title="Leave Ashwani feedback using GitHub" target="_blank"><i class="icon-comment icon-white"></i> Leave me feedback</a></p>




<p>Or click this url:
<a href="https://github.com/TheAshwaniK/Feedback/issues/new">https://github.com/TheAshwaniK/Feedback/issues/new</a></p>




<p>Why Github Repo?? <br/>
So I can keep track of what I have been doing, and addressing your concerns as well.</p>




<p>That's it folks.
Catch you soon.</p>




<p><br/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get More Out Of Google]]></title>
    <link href="http://blog.ashwani.co.in/blog/2013-08-12/get-more-out-of-google/"/>
    <updated>2013-08-12T21:34:00+01:00</updated>
    <id>http://blog.ashwani.co.in/blog/2013-08-12/get-more-out-of-google</id>
    <content type="html"><![CDATA[<p>Recently I stumbled upon an infographics from <a href="http://www.HackCollege.com/">HackCollege</a>      <br/>
So sharing it here.  <br/>
Learn the tricks and Enjoy.
If you need a printable pdf version, head over <a href="http://blog.ashwani.co.in/assets/GetMoreOutOfGoogle.pdf">here</a>
-- Thanks to <a href="http://www.flickr.com/photos/x1brett/6707250233/">Brett</a></p>




<!--more-->




<!-- <object data="/assets/GetMoreOutOfGoogle.pdf" width="1000" height="1000" type='application/pdf'/> -->




<p><br />
<br />
<a href="http://www.hackcollege.com/blog/2011/11/23/infographic-get-more-out-of-google.html">
<img src="http://www.hackcollege.com/wp-content/uploads/2011/11/google.gif " alt="Get  More Out Of Google" width="600" border="1" />
</a></p>

]]></content>
  </entry>
  
</feed>
